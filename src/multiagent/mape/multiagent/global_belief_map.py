"""
Global Belief Map for tracking belief states in multi-agent environments.
Uses Bayesian updates for belief propagation.
"""
import numpy as np
from scipy.spatial import Voronoi
from scipy.ndimage import distance_transform_edt, label, center_of_mass

class GlobalBeliefMap:
    """
    åŸºäºè´å¶æ–¯æ›´æ–°çš„å…¨å±€ä¿¡å¿µåœ°å›¾ï¼Œç”¨äºè·Ÿè¸ªå›¢é˜Ÿå¯¹ç¯å¢ƒçš„ä¿¡å¿µçŠ¶æ€ã€‚
    """
    
    def __init__(self, world_size=2.0, cell_size=0.02, initial_belief=0.5, sensor_fidelity=0.8, landmark_positions=None, landmark_radius=0.05):
        self.world_size = world_size
        self.cell_size = cell_size
        self.initial_belief = initial_belief
        self.sensor_fidelity = sensor_fidelity  # p_s
        self.landmark_positions = landmark_positions if landmark_positions is not None else []

        # è®¡ç®—åœ°å›¾ç»´åº¦: 2 / 0.02 = 100
        self.map_dim = int(world_size / cell_size)
        self.belief_grid = np.full((self.map_dim, self.map_dim), initial_belief, dtype=np.float32)
        
        self.world_min = -world_size / 2.0
        self.world_max = world_size / 2.0
        
        self._precompute_cell_centers()

        self.landmark_map = np.zeros((self.map_dim, self.map_dim), dtype=bool)
        for lx, ly in self.landmark_positions:
            dist_sq = (self.cell_world_x - lx)**2 + (self.cell_world_y - ly)**2
            self.landmark_map |= (dist_sq <= landmark_radius**2)

        self.epsilon = 1e-10
        
    def _precompute_cell_centers(self):
        """é¢„è®¡ç®—æ¯ä¸ªæ …æ ¼ä¸­å¿ƒç‚¹çš„ä¸–ç•Œåæ ‡"""
        grid_x, grid_y = np.meshgrid(
            np.arange(self.map_dim),
            np.arange(self.map_dim),
            indexing='ij'
        )
        
        self.cell_world_x = self.world_min + (grid_x + 0.5) * self.cell_size
        self.cell_world_y = self.world_min + (grid_y + 0.5) * self.cell_size
        
    def reset(self):
        """é‡ç½®åœ°å›¾ï¼Œå°†æ‰€æœ‰æ …æ ¼çš„ä¿¡å¿µæ¢å¤ä¸ºåˆå§‹å€¼"""
        self.belief_grid.fill(self.initial_belief)
        
    def world_to_grid(self, world_pos):
        """å°†ä¸–ç•Œåæ ‡è½¬æ¢ä¸ºæ …æ ¼ç´¢å¼•"""
        x, y = world_pos
        
        if not (self.world_min <= x <= self.world_max and 
                self.world_min <= y <= self.world_max):
            return None
            
        i = int((x - self.world_min) / self.cell_size)
        j = int((y - self.world_min) / self.cell_size)
        
        i = np.clip(i, 0, self.map_dim - 1)
        j = np.clip(j, 0, self.map_dim - 1)
        
        return (i, j)
    
    def get_fov_mask(self, agent_pos, obs_radius):
        """è®¡ç®—æ™ºèƒ½ä½“çš„è§‚æµ‹èŒƒå›´æ©ç """
        x, y = agent_pos
        dist_sq = (self.cell_world_x - x)**2 + (self.cell_world_y - y)**2
        return dist_sq <= obs_radius**2
    
    def bayesian_update(self, positive_mask, negative_mask):
        """ä½¿ç”¨è´å¶æ–¯è§„åˆ™æ›´æ–°ä¿¡å¿µ"""
        # æ­£å‘æ›´æ–°ï¼šæ£€æµ‹åˆ°ç›®æ ‡
        if np.any(positive_mask):
            b_prev = self.belief_grid[positive_mask]
            p_s = self.sensor_fidelity
            
            numerator = p_s * b_prev
            denominator = p_s * b_prev + (1 - p_s) * (1 - b_prev)
            denominator = np.maximum(denominator, self.epsilon)
            
            b_new = numerator / denominator
            b_new = np.clip(b_new, 0.0, 1.0)
            self.belief_grid[positive_mask] = b_new
        
        # è´Ÿå‘æ›´æ–°ï¼šæœªæ£€æµ‹åˆ°ç›®æ ‡
        if np.any(negative_mask):
            b_prev = self.belief_grid[negative_mask]
            p_s = self.sensor_fidelity
            
            numerator = (1 - p_s) * b_prev
            denominator = (1 - p_s) * b_prev + p_s * (1 - b_prev)
            denominator = np.maximum(denominator, self.epsilon)
            
            b_new = numerator / denominator
            b_new = np.clip(b_new, 0.0, 1.0)
            self.belief_grid[negative_mask] = b_new
    
    def update_beliefs(self, agent_positions, obs_radius):
        """
        æ ¹æ®æ™ºèƒ½ä½“è§‚æµ‹å’Œ landmark å®é™…ä½ç½®æ›´æ–°ä¿¡å¿µåœ°å›¾
        
        å‚æ•°:
            agent_positions: æ™ºèƒ½ä½“ä½ç½®åˆ—è¡¨ [(x1, y1), (x2, y2), ...]
            obs_radius: è§‚æµ‹åŠå¾„
        """
        # 1. è®¡ç®—æ‰€æœ‰æ™ºèƒ½ä½“çš„è§‚æµ‹èŒƒå›´ï¼ˆFOVï¼‰
        fov_mask = np.zeros((self.map_dim, self.map_dim), dtype=bool)
        for agent_pos in agent_positions:
            mask = self.get_fov_mask(agent_pos, obs_radius)
            fov_mask |= mask
        
        # 2. æ­£å‘æ›´æ–°ï¼šè¢«è§‚æµ‹åˆ° ä¸” åŒ…å« landmark çš„åŒºåŸŸ
        positive_mask = fov_mask & self.landmark_map
        # 3. è´Ÿå‘æ›´æ–°ï¼šè¢«è§‚æµ‹åˆ° ä½† ä¸åŒ…å« landmark çš„åŒºåŸŸ
        negative_mask = fov_mask & (~self.landmark_map)

        # 4. æ‰§è¡Œè´å¶æ–¯æ›´æ–°
        self.bayesian_update(positive_mask, negative_mask)
    
    def compute_shannon_entropy(self):
        """è®¡ç®—æ¯ä¸ªæ …æ ¼çš„é¦™å†œç†µ"""
        b = self.belief_grid
        
        with np.errstate(divide='ignore', invalid='ignore'):
            entropy = np.where(
                (b > self.epsilon) & (b < 1 - self.epsilon),
                -(b * np.log2(b) + (1 - b) * np.log2(1 - b)),
                0.0
            )
        
        return entropy
    
    def get_total_uncertainty(self):
        """è®¡ç®—æ•´ä¸ªåœ°å›¾çš„æ€»ä¸ç¡®å®šæ€§"""
        entropy = self.compute_shannon_entropy()
        return np.sum(entropy)
    
    def get_mean_uncertainty(self):
        """è®¡ç®—æ•´ä¸ªåœ°å›¾çš„å¹³å‡ä¸ç¡®å®šæ€§"""
        entropy = self.compute_shannon_entropy()
        return np.mean(entropy)
    
    def get_high_uncertainty_positions(self, threshold=0.9):
        """è·å–é«˜ä¸ç¡®å®šæ€§åŒºåŸŸçš„ä½ç½®"""
        entropy = self.compute_shannon_entropy()
        max_entropy = 1.0
        
        high_uncertainty_mask = entropy >= (threshold * max_entropy)
        indices = np.argwhere(high_uncertainty_mask)
        
        return [(int(i), int(j)) for i, j in indices]
    
    def grid_to_world(self, grid_pos):
        """å°†æ …æ ¼ç´¢å¼•è½¬æ¢ä¸ºä¸–ç•Œåæ ‡"""
        i, j = grid_pos
        x = self.world_min + (i + 0.5) * self.cell_size
        y = self.world_min + (j + 0.5) * self.cell_size
        return (x, y)
    
    def get_belief_at_position(self, world_pos):
        """è·å–æŒ‡å®šä¸–ç•Œåæ ‡å¤„çš„ä¿¡å¿µå€¼"""
        grid_pos = self.world_to_grid(world_pos)
        if grid_pos is None:
            return None
        
        i, j = grid_pos
        return self.belief_grid[i, j]
    
    def visualize_beliefs(self):
        """è¿”å›ä¿¡å¿µåœ°å›¾çš„å‰¯æœ¬"""
        return self.belief_grid.copy()
    
    def visualize_entropy(self):
        """è¿”å›ç†µåœ°å›¾çš„å‰¯æœ¬"""
        return self.compute_shannon_entropy()
    
    def compute_voronoi_regions(self, agent_positions):
        """
        åŸºäºæ™ºèƒ½ä½“ä½ç½®è®¡ç®—VoronoiåŒºåŸŸåˆ’åˆ†ï¼ˆå‘é‡åŒ–ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        """
        if len(agent_positions) == 0:
            return None
        
        # å°†æ™ºèƒ½ä½“ä½ç½®è½¬æ¢ä¸ºæ …æ ¼ç´¢å¼•
        agent_grids = []
        for pos in agent_positions:
            grid_pos = self.world_to_grid(pos)
            if grid_pos is not None:
                agent_grids.append(grid_pos)
            else:
                x, y = pos
                x = np.clip(x, self.world_min, self.world_max)
                y = np.clip(y, self.world_min, self.world_max)
                grid_pos = self.world_to_grid((x, y))
                agent_grids.append(grid_pos)
        
        agent_grids = np.array(agent_grids)
        
        # ğŸš€ å‘é‡åŒ–ä¼˜åŒ–ï¼šåˆ›å»ºæ …æ ¼ç½‘æ ¼
        grid_i, grid_j = np.meshgrid(
            np.arange(self.map_dim), 
            np.arange(self.map_dim), 
            indexing='ij'
        )
        
        # ğŸš€ å‘é‡åŒ–ä¼˜åŒ–ï¼šä¸ºæ¯ä¸ªæ™ºèƒ½ä½“è®¡ç®—åˆ°æ‰€æœ‰æ …æ ¼çš„è·ç¦»
        voronoi_map = np.zeros((self.map_dim, self.map_dim), dtype=np.int32)
        min_dist_map = np.full((self.map_dim, self.map_dim), np.inf)
        
        for agent_idx, (ai, aj) in enumerate(agent_grids):
            # å‘é‡åŒ–è·ç¦»è®¡ç®—
            dist_map = np.sqrt((grid_i - ai)**2 + (grid_j - aj)**2)
            
            # æ›´æ–° Voronoi åŒºåŸŸ
            mask = dist_map < min_dist_map
            voronoi_map[mask] = agent_idx
            min_dist_map[mask] = dist_map[mask]
        
        return voronoi_map
    
    def compute_entropy_weighted_centroids(self, agent_positions):
        """
        è®¡ç®—æ¯ä¸ªæ™ºèƒ½ä½“VoronoiåŒºåŸŸçš„é¦™å†œç†µåŠ æƒè´¨å¿ƒï¼ˆå‘é‡åŒ–ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        """
        if len(agent_positions) == 0:
            return []
        
        voronoi_map = self.compute_voronoi_regions(agent_positions)
        entropy_map = self.compute_shannon_entropy()
        
        centroids = []
        
        for agent_idx in range(len(agent_positions)):
            region_mask = (voronoi_map == agent_idx)
            
            # ğŸš€ å‘é‡åŒ–ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨é¢„è®¡ç®—çš„ä¸–ç•Œåæ ‡æ•°ç»„
            region_world_x = self.cell_world_x[region_mask]
            region_world_y = self.cell_world_y[region_mask]
            region_entropies = entropy_map[region_mask]
            
            if len(region_entropies) == 0:
                centroids.append(agent_positions[agent_idx])
                continue
            
            total_entropy = np.sum(region_entropies)
            
            if total_entropy < self.epsilon:
                centroids.append(agent_positions[agent_idx])
                continue
            
            # ğŸš€ å‘é‡åŒ–ä¼˜åŒ–ï¼šä¸€æ¬¡æ€§è®¡ç®—åŠ æƒè´¨å¿ƒ
            centroid_x = np.sum(region_world_x * region_entropies) / total_entropy
            centroid_y = np.sum(region_world_y * region_entropies) / total_entropy
            
            centroids.append((float(centroid_x), float(centroid_y)))
    
        return centroids
    
    def get_voronoi_region_stats(self, agent_positions):
        """è·å–æ¯ä¸ªæ™ºèƒ½ä½“VoronoiåŒºåŸŸçš„ç»Ÿè®¡ä¿¡æ¯"""
        voronoi_map = self.compute_voronoi_regions(agent_positions)
        entropy_map = self.compute_shannon_entropy()
        centroids = self.compute_entropy_weighted_centroids(agent_positions)
        
        stats = []
        
        for agent_idx in range(len(agent_positions)):
            region_mask = (voronoi_map == agent_idx)
            
            area = np.sum(region_mask)
            total_entropy = np.sum(entropy_map[region_mask])
            mean_entropy = np.mean(entropy_map[region_mask]) if area > 0 else 0.0
            mean_belief = np.mean(self.belief_grid[region_mask]) if area > 0 else 0.5
            
            stats.append({
                'agent_idx': agent_idx,
                'area': int(area),
                'total_entropy': float(total_entropy),
                'mean_entropy': float(mean_entropy),
                'centroid': centroids[agent_idx],
                'mean_belief': float(mean_belief)
            })
        
        return stats
    
    def detect_targets(self, belief_threshold=0.95):
        """æ£€æµ‹ä¿¡å¿µåœ°å›¾ä¸­çš„ç›®æ ‡ç‚¹"""
        binary_map = (self.belief_grid > belief_threshold).astype(np.int8)
        
        structure = np.ones((3, 3), dtype=np.int8)
        cluster_labels, num_clusters = label(binary_map, structure=structure)
        
        target_positions = []
        target_grid_positions = []
        cluster_sizes = []
        
        for cluster_id in range(1, num_clusters + 1):
            cluster_mask = (cluster_labels == cluster_id)
            size = np.sum(cluster_mask)
            cluster_sizes.append(size)
            
            grid_centroid = center_of_mass(cluster_mask)
            i_center, j_center = int(round(grid_centroid[0])), int(round(grid_centroid[1]))
            
            i_center = np.clip(i_center, 0, self.map_dim - 1)
            j_center = np.clip(j_center, 0, self.map_dim - 1)
            
            target_grid_positions.append((i_center, j_center))
            world_pos = self.grid_to_world((i_center, j_center))
            target_positions.append(world_pos)
        
        return {
            'binary_map': binary_map,
            'num_targets': num_clusters,
            'target_positions': target_positions,
            'target_grid_positions': target_grid_positions,
            'cluster_sizes': cluster_sizes,
            'cluster_labels': cluster_labels
        }
    
    def get_target_positions(self, belief_threshold=0.95, min_cluster_size=1):
        """ç›´æ¥è¿”å›æ£€æµ‹åˆ°çš„ç›®æ ‡ç‚¹ä¸–ç•Œåæ ‡"""
        result = self.detect_targets(belief_threshold)
        
        if min_cluster_size > 1:
            filtered_positions = []
            for pos, size in zip(result['target_positions'], result['cluster_sizes']):
                if size >= min_cluster_size:
                    filtered_positions.append(pos)
            return filtered_positions
        
        return result['target_positions']
    
    def visualize_detected_targets(self, belief_threshold=0.95):
        """å¯è§†åŒ–æ£€æµ‹åˆ°çš„ç›®æ ‡ç‚¹"""
        result = self.detect_targets(belief_threshold)
        
        vis_map = result['cluster_labels'].astype(np.float32)
        
        for grid_pos in result['target_grid_positions']:
            i, j = grid_pos
            vis_map[i, j] = -1
        
        result['visualization_map'] = vis_map
        return result
    
    def get_targets_summary(self, belief_threshold=0.95):
        """è·å–ç›®æ ‡æ£€æµ‹çš„æ‘˜è¦ä¿¡æ¯"""
        result = self.detect_targets(belief_threshold)
        
        summary = {
            'num_targets': result['num_targets'],
            'total_high_belief_cells': np.sum(result['binary_map']),
            'mean_cluster_size': np.mean(result['cluster_sizes']) if result['cluster_sizes'] else 0,
            'max_cluster_size': max(result['cluster_sizes']) if result['cluster_sizes'] else 0,
            'min_cluster_size': min(result['cluster_sizes']) if result['cluster_sizes'] else 0,
            'target_positions': result['target_positions']
        }
        
        return summary

