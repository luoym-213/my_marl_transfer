import torch
import torch.nn as nn
import numpy as np
from rlcore.distributions import Categorical
import torch.nn.functional as F
import math
from scipy.optimize import linear_sum_assignment  # åŒˆç‰™åˆ©ç®—æ³•
from torch.distributions import Categorical as TorchCategorical
from planning.rrt_GNN import RRT_GNN, plan_batch

def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1 or classname.find('Linear') != -1:
        nn.init.orthogonal_(m.weight.data)
        if m.bias is not None:
            m.bias.data.fill_(0)


class MPNN(nn.Module):
    def __init__(self, action_space, num_agents, num_entities, input_size=16, hidden_dim=128, embed_dim=None,
                 pos_index=2, norm_in=False, nonlin=nn.ReLU, n_heads=3, mask_dist=None, mask_obs_dist=None, entity_mp=False, is_recurrent=True):
        super().__init__()

        # ==================== åŸºç¡€é…ç½® ====================
        self.h_dim = hidden_dim
        self.nonlin = nonlin
        self.num_agents = num_agents # number of agents
        self.num_entities = num_entities # number of entities
        self.low_level_input = 2 + 2*num_agents # low level input size: agent pos + all agents pos
        self.K = 3 # message passing rounds
        self.embed_dim = self.h_dim if embed_dim is None else embed_dim
        self.n_heads = n_heads
        self.is_recurrent = is_recurrent
        self.mask_dist = mask_dist
        self.mask_obs_dist = mask_obs_dist
        self.input_size = input_size # è¿™é‡Œæ˜¯agengtè‡ªèº«é€Ÿåº¦ä½ç½®ï¼ˆ4ï¼‰
        self.entity_mp = entity_mp
        # this index must be from the beginning of observation vector
        self.pos_index = pos_index
        # task generation parameters
        self.task_dim = 2
        self.h_dim2 = self.h_dim // 2 # 64
        num_actions = action_space.n

        # ==================== æ¨¡å—åŒ–ç½‘ç»œ ====================
        self.modules_dict = nn.ModuleDict()
        
        # 1. åº•å±‚ç­–ç•¥ç½‘ç»œ
        self.modules_dict['low_level'] = self._build_low_level_modules(action_space)
        
        # 2. é«˜å±‚ç­–ç•¥ç½‘ç»œ
        self.modules_dict['high_level'] = self._build_high_level_modules()
        
        # 3. é«˜å±‚ Critic
        self.modules_dict['high_critic'] = self._build_high_critic_modules()

        # ==================== å…¶ä»–å±æ€§ ====================
        if norm_in:
            self.in_fn = nn.BatchNorm1d(self.input_size)
            self.in_fn.weight.data.fill_(1)
            self.in_fn.bias.data.fill_(0)
        else:
            self.in_fn = lambda x: x
        self.apply(weights_init)
        self.attn_mat = np.ones((num_agents, num_agents))
        self.dropout_mask = None     
        

        # self.value_head = nn.Sequential(nn.Linear(self.h_dim, self.h_dim),
        #                                 self.nonlin(inplace=True),
        #                                 nn.Linear(self.h_dim,1))

        # self.policy_head = nn.Sequential(nn.Linear(self.h_dim, self.h_dim),
        #                                  self.nonlin(inplace=True))

        # self.low_agent_encoder = nn.Sequential(nn.Linear(self.low_level_input, self.h_dim),
        #                                       self.nonlin(inplace=True))
        
        # ==================== ä»£åŠ ====================
        self.dist = Categorical(self.h_dim,num_actions)

    # ==================== æ¨¡å—æ„å»ºå‡½æ•° ====================
    def _build_low_level_modules(self, action_space):
        """æ„å»ºåº•å±‚ç­–ç•¥ç½‘ç»œ"""
        num_actions = action_space.n
        low_level = nn.ModuleDict({
            'encoder': nn.Sequential(
                nn.Linear(self.low_level_input, self.h_dim),
                self.nonlin(inplace=True)
            ),
            'value_head': nn.Sequential(
                nn.Linear(self.h_dim, self.h_dim),
                self.nonlin(inplace=True),
                nn.Linear(self.h_dim, 1)
            ),
            'policy_head': nn.Sequential(
                nn.Linear(self.h_dim, self.h_dim),
                self.nonlin(inplace=True)
            ),
            'dist': Categorical(self.h_dim, num_actions)
        })
        
        return low_level

    def _build_high_level_modules(self):
        """æ„å»ºé«˜å±‚ç­–ç•¥ç½‘ç»œï¼ˆActorï¼‰"""
        high_level = nn.ModuleDict({
            # åœ°å›¾ç¼–ç å™¨
            'map_conv1': nn.Sequential(
                nn.Conv2d(4, 16, kernel_size=5, stride=2, padding=2),
                nn.ReLU()
            ),
            'map_conv2': nn.Sequential(
                nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),
                nn.ReLU()
            ),
            'map_conv3': nn.Sequential(
                nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=0),
                nn.ReLU()
            ),
            
            # å‘é‡ç¼–ç å™¨
            'vec_mlp': nn.Sequential(
                nn.Linear(5, 32),
                nn.ReLU(),
                nn.Linear(32, 64),
                nn.ReLU()
            ),
            
            # ===== åŠ¨æ€å›¾æ¨ç†æ¨¡å— =====
            # EgoèŠ‚ç‚¹ç¼–ç å™¨ [5] -> [64]
            'ego_node_encoder': nn.Sequential(
                nn.Linear(5, 32),
                nn.ReLU(),
                nn.Linear(32, 64),
                nn.ReLU()
            ),
            
            # ExploreèŠ‚ç‚¹ç¼–ç å™¨ [4] -> [64]
            'explore_node_encoder': nn.Sequential(
                nn.Linear(4, 32),
                nn.ReLU(),
                nn.Linear(32, 64),
                nn.ReLU()
            ),
            
            # LandmarkèŠ‚ç‚¹ç¼–ç å™¨ [4] -> [64]
            'landmark_node_encoder': nn.Sequential(
                nn.Linear(4, 32),
                nn.ReLU(),
                nn.Linear(32, 64),
                nn.ReLU()
            ),
            
            # è¾¹ç¼–ç å™¨ [3] -> [32]
            'edge_encoder': nn.Sequential(
                nn.Linear(3, 32),
                nn.ReLU()
            ),
            
            # æ³¨æ„åŠ›æŠ•å½±å±‚
            'q_proj': nn.Linear(64, 64),  # ego -> query
            'k_proj': nn.Linear(96, 64),  # node(64) + edge(32) -> key
            'v_proj': nn.Linear(96, 64),  # node(64) + edge(32) -> value
            
            # èŠ‚ç‚¹é€‰æ‹©å¤´ï¼ˆç»Ÿä¸€å¯¹æ‰€æœ‰èŠ‚ç‚¹æ‰“åˆ†ï¼‰
            'node_selection_head': nn.Linear(64, 1),
            
            # å†³ç­–å¤´ï¼ˆä¿ç•™ç”¨äºå…¶ä»–ç”¨é€”ï¼Œå¦‚æœä¸éœ€è¦å¯ä»¥åˆ é™¤ï¼‰
            'decision_head': nn.Sequential(
                nn.Linear(128, 64),
                nn.ReLU(),
                nn.Linear(64, 2)
            ),
            
            # æ¢ç´¢ç‚¹è§£ç å™¨
            'decoder_fuse': nn.Sequential(
                nn.Conv2d(192, 64, kernel_size=1),
                nn.ReLU()
            ),
            'decoder_up1': nn.Sequential(
                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),
                nn.Conv2d(64, 32, kernel_size=3, padding=1),
                nn.ReLU()
            ),
            'decoder_up2': nn.Sequential(
                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),
                nn.Conv2d(32, 16, kernel_size=3, padding=1),
                nn.ReLU()
            ),
            'decoder_out': nn.Sequential(
                nn.Upsample(size=(100, 100), mode='bilinear', align_corners=False),
                nn.Conv2d(16, 1, kernel_size=1)
            )
        })
        
        return high_level

    def _build_high_critic_modules(self):
        """æ„å»ºé«˜å±‚ Critic"""
        high_critic = nn.ModuleDict({
            # å…¨å±€åœ°å›¾ç¼–ç å™¨ [B, 3, H, W] -> [B, 256]
            'map_backbone': nn.Sequential(
                nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2),
                nn.ReLU(),
                nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),
                nn.ReLU(),
                nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
                nn.ReLU(),
                nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=0),
                nn.ReLU()
            ),
            'map_compress': nn.Sequential(
                nn.Linear(64 * 6 * 6, 256),
                nn.ReLU()
            ),
            
            # å•ä¸ªæ™ºèƒ½ä½“çŠ¶æ€ç¼–ç å™¨ [4] -> [64]
            'agent_encoder': nn.Sequential(
                nn.Linear(4, 32),  # [x, y, x_g, y_g]
                nn.ReLU(),
                nn.Linear(32, 64),
                nn.ReLU()
            ),
            
            # èåˆå±‚ï¼šå…¨å±€ç‰¹å¾(256) + æ™ºèƒ½ä½“ç‰¹å¾(64) -> ä»·å€¼
            'fusion_layer': nn.Sequential(
                nn.Linear(256 + 64, 128),
                nn.ReLU(),
                nn.Linear(128, 128),
                nn.ReLU()
            )
        })
        
        # æ¯ä¸ªæ™ºèƒ½ä½“çš„ç‹¬ç«‹ä»·å€¼è¾“å‡ºå¤´
        high_critic['value_heads'] = nn.ModuleList([
            nn.Linear(128, 1) for _ in range(self.num_agents)
        ])
        
        return high_critic

    # ==================== å‚æ•°ç®¡ç†æ¥å£ ====================
    
    def get_module_params(self, module_name):
        """
        è·å–æŒ‡å®šæ¨¡å—çš„å‚æ•°
        
        Args:
            module_name: 'shared', 'low_level', 'high_level', 'high_critic'
        
        Returns:
            list of parameters
        """
        if module_name not in self.modules_dict:
            raise ValueError(f"Module '{module_name}' not found! Available: {list(self.modules_dict.keys())}")
        
        return list(self.modules_dict[module_name].parameters())

    def freeze_module(self, module_name):
        """å†»ç»“æŒ‡å®šæ¨¡å—çš„å‚æ•°"""
        for param in self.get_module_params(module_name):
            param.requires_grad = False
        print(f"âœ… Module '{module_name}' frozen")

    def unfreeze_module(self, module_name):
        """è§£å†»æŒ‡å®šæ¨¡å—çš„å‚æ•°"""
        for param in self.get_module_params(module_name):
            param.requires_grad = True
        print(f"âœ… Module '{module_name}' unfrozen")

    def save_module_checkpoint(self, module_name, path):
        """
        ä¿å­˜æŒ‡å®šæ¨¡å—çš„å‚æ•°
        
        Args:
            module_name: æ¨¡å—åç§°
            path: ä¿å­˜è·¯å¾„
        """
        if module_name not in self.modules_dict:
            raise ValueError(f"Module '{module_name}' not found!")
        
        checkpoint = {
            'module_name': module_name,
            'state_dict': self.modules_dict[module_name].state_dict(),
            'config': {
                'num_agents': self.num_agents,
                'num_entities': self.num_entities,
                'hidden_dim': self.h_dim,
                'embed_dim': self.embed_dim
            }
        }
        
        torch.save(checkpoint, path)
        print(f"âœ… Saved '{module_name}' checkpoint to {path}")

    def load_module_checkpoint(self, module_name, path, strict=True, freeze=False):
        """
        åŠ è½½æŒ‡å®šæ¨¡å—çš„å‚æ•°
        
        Args:
            module_name: æ¨¡å—åç§°
            path: checkpoint è·¯å¾„
            strict: æ˜¯å¦ä¸¥æ ¼åŒ¹é…å‚æ•°
            freeze: æ˜¯å¦åŠ è½½åå†»ç»“
        
        Returns:
            missing_keys, unexpected_keys
        """
        checkpoint = torch.load(path, map_location='cpu')
        
        # éªŒè¯é…ç½®
        if 'config' in checkpoint:
            config = checkpoint['config']
            if config.get('num_agents') != self.num_agents:
                print(f"âš ï¸ Warning: num_agents mismatch! "
                      f"Checkpoint: {config['num_agents']}, Current: {self.num_agents}")
        
        # åŠ è½½å‚æ•°
        missing, unexpected = self.modules_dict[module_name].load_state_dict(
            checkpoint['state_dict'], 
            strict=strict
        )
        
        if freeze:
            self.freeze_module(module_name)
        
        print(f"âœ… Loaded '{module_name}' checkpoint from {path}")
        if missing:
            print(f"  Missing keys: {missing}")
        if unexpected:
            print(f"  Unexpected keys: {unexpected}")
        
        return missing, unexpected

    def save_all_modules(self, save_dir):
        """ä¿å­˜æ‰€æœ‰æ¨¡å—åˆ°æŒ‡å®šç›®å½•"""
        import os
        os.makedirs(save_dir, exist_ok=True)
        
        for module_name in self.modules_dict.keys():
            save_path = os.path.join(save_dir, f"{module_name}.pth")
            self.save_module_checkpoint(module_name, save_path)

    def load_pretrained_low_level(self, path, freeze=True):
        """
        æ™ºèƒ½åŠ è½½å‡½æ•°ï¼šæ”¯æŒåŠ è½½ 'æ¨¡å—åŒ–Checkpoint' æˆ– 'å®Œæ•´è®­ç»ƒCheckpoint'
        """
        print(f"ğŸ”„ Loading low-level params from {path}...")
        checkpoint = torch.load(path, map_location='cpu')
        
        low_level_state_dict = {}
        
        # === æƒ…å†µ A: è¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ– Checkpoint ===
        if 'state_dict' in checkpoint:
            print("  Type: Module Checkpoint")
            low_level_state_dict = checkpoint['state_dict']
            
        # === æƒ…å†µ B: è¿™æ˜¯ä¸€ä¸ªå®Œæ•´è®­ç»ƒ Checkpoint ===
        elif 'models' in checkpoint:
            print("  Type: Full Training Checkpoint (extracting params...)")
            full_state_dict = checkpoint['models'][0]
            
            # â­ å…³é”®ä¿®æ”¹ï¼šæ˜ç¡®åº•å±‚ç½‘ç»œçš„é”®åå‰ç¼€
            # æ—§ä»£ç ä¸­ï¼Œåº•å±‚ç½‘ç»œçš„é”®ååº”è¯¥æ˜¯ 'low_agent_encoder.*', 'value_head.*' ç­‰
            target_keys = [
                'low_agent_encoder',  # â† è¿™æ˜¯åº•å±‚ç¼–ç å™¨çš„çœŸæ­£åå­—
                'value_head',
                'policy_head',
                'dist'
            ]
            
            for key, value in full_state_dict.items():
                # å»é™¤å¯èƒ½çš„ 'modules_dict.low_level.' å‰ç¼€ï¼ˆå¦‚æœæ˜¯æ–°ç‰ˆä»£ç ä¿å­˜çš„ï¼‰
                clean_key = key.replace('modules_dict.low_level.', '')
                
                # æ£€æŸ¥æ˜¯å¦å±äºåº•å±‚ç½‘ç»œï¼ˆå¿…é¡»å®Œæ•´åŒ¹é…å‰ç¼€ï¼‰
                if any(clean_key.startswith(prefix) for prefix in target_keys):
                    # â­ å¦‚æœæ˜¯æ—§ä»£ç ï¼Œéœ€è¦å°† 'low_agent_encoder' æ˜ å°„ä¸º 'encoder'
                    # å› ä¸ºæ–°ä»£ç ä¸­åº•å±‚æ¨¡å—å†…éƒ¨çš„åå­—æ˜¯ 'encoder'
                    final_key = clean_key.replace('low_agent_encoder', 'encoder')
                    low_level_state_dict[final_key] = value
                    
        else:
            raise ValueError(f"Unknown checkpoint format! Keys found: {list(checkpoint.keys())}")

        # åŠ è½½å‚æ•°
        missing, unexpected = self.modules_dict['low_level'].load_state_dict(
            low_level_state_dict, 
            strict=False 
        )
        
        if freeze:
            self.freeze_module('low_level')
            
        print(f"âœ… Low-level loaded. Missing keys: {len(missing)}, Unexpected keys: {len(unexpected)}")
        if missing:
            print(f"  âš ï¸ Missing: {missing}")
        if unexpected:
            print(f"  âš ï¸ Unexpected: {unexpected}")
        
        return missing, unexpected
        """
        ä¾¿æ·å‡½æ•°ï¼šåŠ è½½é¢„è®­ç»ƒçš„åº•å±‚ç½‘ç»œ
        
        Args:
            path: checkpoint è·¯å¾„
            freeze: æ˜¯å¦å†»ç»“å‚æ•°
        """
        # return self.load_module_checkpoint('low_level', path, strict=False, freeze=freeze)

    def get_trainable_params_by_modules(self, module_names, learning_rates=None):
        """
        è·å–å¤šä¸ªæ¨¡å—çš„å‚æ•°ç»„ï¼ˆç”¨äºä¼˜åŒ–å™¨ï¼‰
        
        Args:
            module_names: æ¨¡å—åç§°åˆ—è¡¨
            learning_rates: å¯¹åº”çš„å­¦ä¹ ç‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            param_groups for optimizer
        
        Example:
            >>> param_groups = model.get_trainable_params_by_modules(
            ...     ['high_level', 'high_critic', 'low_level'],
            ...     [3e-4, 3e-4, 1e-5]  # åº•å±‚ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡
            ... )
            >>> optimizer = torch.optim.Adam(param_groups)
        """
        param_groups = []
        
        if learning_rates is None:
            learning_rates = [None] * len(module_names)
        
        for module_name, lr in zip(module_names, learning_rates):
            params = self.get_module_params(module_name)
            if lr is not None:
                param_groups.append({'params': params, 'lr': lr})
            else:
                param_groups.append({'params': params})
        
        return param_groups

    # ==================== å‰å‘ä¼ æ’­æ¥å£ï¼ˆä¿æŒå…¼å®¹ï¼‰====================
    
    @property
    def low_agent_encoder(self):
        return self.modules_dict['low_level']['encoder']
    
    @property
    def value_head(self):
        return self.modules_dict['low_level']['value_head']
    
    @property
    def policy_head(self):
        return self.modules_dict['low_level']['policy_head']
    
    @property
    def dist(self):
        return self.modules_dict['low_level']['dist']
    
    @property
    def map_conv1(self):
        return self.modules_dict['high_level']['map_conv1']
    
    @property
    def map_conv2(self):
        return self.modules_dict['high_level']['map_conv2']
    
    @property
    def map_conv3(self):
        return self.modules_dict['high_level']['map_conv3']
    
    @property
    def vec_mlp(self):
        return self.modules_dict['high_level']['vec_mlp']
    
    @property
    def decision_head(self):
        return self.modules_dict['high_level']['decision_head']
    
    @property
    def decoder_fuse(self):
        return self.modules_dict['high_level']['decoder_fuse']
    
    @property
    def decoder_up1(self):
        return self.modules_dict['high_level']['decoder_up1']
    
    @property
    def decoder_up2(self):
        return self.modules_dict['high_level']['decoder_up2']
    
    @property
    def decoder_out(self):
        return self.modules_dict['high_level']['decoder_out']
    
    @property
    def critic_map_backbone(self):
        return self.modules_dict['high_critic']['map_backbone']
    
    @property
    def critic_map_compress(self):
        return self.modules_dict['high_critic']['map_compress']
    
    @property
    def critic_agent_encoder(self):
        return self.modules_dict['high_critic']['agent_encoder']
    
    @property
    def critic_fusion_layer(self):
        return self.modules_dict['high_critic']['fusion_layer']
    
    @property
    def critic_value_out_heads(self):
        return self.modules_dict['high_critic']['value_heads']
    
    @property
    def critic_map_flat_dim(self):
        return 64 * 6 * 6
    
    @property
    def ego_node_encoder(self):
        return self.modules_dict['high_level']['ego_node_encoder']
    
    @property
    def explore_node_encoder(self):
        return self.modules_dict['high_level']['explore_node_encoder']
    
    @property
    def landmark_node_encoder(self):
        return self.modules_dict['high_level']['landmark_node_encoder']
    
    @property
    def edge_encoder(self):
        return self.modules_dict['high_level']['edge_encoder']
    
    @property
    def q_proj(self):
        return self.modules_dict['high_level']['q_proj']
    
    @property
    def k_proj(self):
        return self.modules_dict['high_level']['k_proj']
    
    @property
    def v_proj(self):
        return self.modules_dict['high_level']['v_proj']
    
    @property
    def node_selection_head(self):
        return self.modules_dict['high_level']['node_selection_head']
    
    @property
    def attn_dim(self):
        return 64

    def get_explore_nodes(self, vec_inp, map_inp, agent_indices=None, deterministic=False):
        """
        vec_inp: [Batch, num_agents, 4]ï¼Œä¸–ç•Œåæ ‡ï¼š[x_pos, y_pos, x_goal, y_goal]
        map_inp: [2, Batch, num_agents, H, W], (0: entropy, 1: voronoi_mask)
        agent_indices: [N] å¯é€‰ï¼Œä»…åœ¨éƒ¨åˆ†æ™ºèƒ½ä½“æ›´æ–°æ—¶æä¾›
        """

        # 1. é€šè¿‡RRTç”Ÿæˆå€™é€‰ç›®æ ‡ç‚¹
        ## è¾“å…¥vec_inp:[Batch, 2], map_inp:[2,Batch, H, W]
        ## è¾“å‡ºå€™é€‰ç›®æ ‡ç‚¹B_candidate:[Batch, K, 3]ï¼Œç¦»æ•£æ …æ ¼åæ ‡
        ### vec_inpè½¬åŒ–ä¸ºç¦»æ•£æ …æ ¼åæ ‡
        B_pro = vec_inp.size(0) 
        if agent_indices is not None:
            # agent_indices: [B_pro]
            batch_idx = torch.arange(B_pro, device=vec_inp.device)
            
            # [B_pro, num_agents, 4] -> [B_pro, 1, 4]
            update_nodes = vec_inp[batch_idx, agent_indices].unsqueeze(1)
            
            # [2, B_pro, num_agents, H, W] -> [B_pro, 1, H, W]
            voronoi_np = map_inp[1, batch_idx, agent_indices].unsqueeze(1).detach().cpu().numpy().astype(bool)
            entropy_np = map_inp[0, batch_idx, agent_indices].unsqueeze(1).detach().cpu().numpy().astype(np.float32)
        else:
            update_nodes = vec_inp
            voronoi_np = map_inp[1].detach().cpu().numpy().astype(bool)
            entropy_np = map_inp[0].detach().cpu().numpy().astype(np.float32)

        B_agents = update_nodes.size(1) # å¦‚æœæŒ‡å®šäº†indicesï¼Œè¿™é‡Œæ˜¯1ï¼›å¦åˆ™æ˜¯num_agents        

        # update_nodes: [B_pro, B_agents, 4] -> é€‰å–ä½ç½®éƒ¨åˆ† [B_pro*B_agents, 2]
        starte_nodes = self._world_to_grid_torch(update_nodes.view(-1, update_nodes.size(2))[:, :2], H=100, W=100)  # [B_pro*B_agents, 2] æ•´æ•°æ …æ ¼åæ ‡
        voronoi_inp = voronoi_np.reshape(-1, voronoi_np.shape[-2], voronoi_np.shape[-1])  # [B_pro*B_agents, H, W]
        entropy_inp = entropy_np.reshape(-1, entropy_np.shape[-2], entropy_np.shape[-1])  # [B_pro*B_agents, H, W]
        
        batch_rtt = plan_batch(starte_nodes, voronoi_inp, entropy_inp, max_iterations=60, top_k=5)  # [B_pro*B_agents, K, 3]
        batch_rtt = torch.tensor(batch_rtt, dtype=torch.long, device=vec_inp.device).view(B_pro, B_agents, -1, 3)  # [B_pro, B_agents, K, 3]
        
        ## è½¬ä¸ºä¸–ç•Œåæ ‡
        explore_nodes_world = self._grid_to_world_torch(batch_rtt[..., :2].float(), H=100, W=100)  # [B_pro, B_agents, K, 2]
        
        # update_nodes: [B_pro, B_agents, 4]ï¼Œå‰ä¸¤ç»´æ˜¯ ego çš„ä½ç½®
        ego_positions = update_nodes[..., :2]  # [B_pro, B_agents, 2]
        
        # å¹¿æ’­å‡æ³•ï¼šexplore_nodes_world [B_pro, B_agents, K, 2] - ego_positions [B_pro, B_agents, 1, 2]
        relative_explore_positions = explore_nodes_world - ego_positions.unsqueeze(2)  # [B_pro, B_agents, K, 2]
        
        ## æ‹¼æ¥æˆå€™é€‰ç‚¹ç‰¹å¾ï¼ˆç°åœ¨å‰ä¸¤ç»´æ˜¯ç›¸å¯¹ä½ç½®ï¼‰
        explore_nodes = torch.cat([relative_explore_positions, batch_rtt[..., 2:3].float()], dim=-1)  # [B_pro, B_agents, K, 3]

        ## è¡¥å……å€™é€‰ç‚¹èŠ‚ç‚¹ç‰¹å¾ - Occupied Feature
        d0 = 0.3
        # æå–æ‰€æœ‰æ™ºèƒ½ä½“çš„ç›®æ ‡ä½ç½® [B_pro, num_agents, 2]
        all_goals = vec_inp[..., 2:4]        
        
        # è®¡ç®—è·ç¦»çŸ©é˜µï¼ˆè¿™é‡Œä»ç„¶ä½¿ç”¨ç»å¯¹ä½ç½®è®¡ç®—è·ç¦»ï¼‰
        # explore_nodes_world: [B_pro, B_agents, K, 2]ï¼ˆç»å¯¹ä½ç½®ï¼‰
        # all_goals: [B_pro, num_agents, 2]ï¼ˆç»å¯¹ä½ç½®ï¼‰
        dists = torch.norm(explore_nodes_world.unsqueeze(3) - all_goals.unsqueeze(1).unsqueeze(1), dim=-1)

        mask = torch.ones_like(dists, dtype=torch.bool)
        if agent_indices is not None:
            batch_idx = torch.arange(B_pro, device=vec_inp.device)
            mask[batch_idx, 0, :, agent_indices] = False
        else:
            diag_mask = torch.eye(B_agents, device=vec_inp.device).bool()
            mask = ~diag_mask.view(1, B_agents, 1, B_agents).expand(B_pro, B_agents, 5, B_agents)

        dists = torch.where(mask, dists, torch.tensor(float('inf'), device=dists.device))

        valid_mask = (dists < d0)
        occ_vals = ((d0 - dists) / d0).pow(2)
        occ_vals = torch.where(valid_mask, occ_vals, torch.tensor(0.0, device=dists.device))
        
        occupied_feature = occ_vals.sum(dim=-1, keepdim=True) # [B_pro, B_agents, K, 1]
        
        # âœ… æœ€ç»ˆçš„ explore_nodes: [B_pro, B_agents, K, 4]
        # å‰ä¸¤ç»´æ˜¯ç›¸å¯¹ä½ç½®ï¼Œç¬¬ä¸‰ç»´æ˜¯ç†µå€¼ï¼Œç¬¬å››ç»´æ˜¯ occupied ç‰¹å¾
        explore_nodes = torch.cat([explore_nodes, occupied_feature], dim=-1)  # [B_pro, B_agents, K, 4]

        return explore_nodes

    def get_landmark_nodes(self, agent_positions, detected, detected_mask, linear_indices):
        """
        agent_positions: [num_agents * num_processes, 2]ï¼Œä¸–ç•Œåæ ‡
        detected: [num_agents * num_processes, max_landmarks, 4]ï¼Œlandmarkç‰¹å¾ [x, y, utility, is_targeted]
        detected_mask: [num_agents * num_processes, max_landmarks, 1]ï¼Œå€™é€‰ç‚¹æœ‰æ•ˆæ©ç 
        linear_indices: [N]ï¼Œéœ€è¦å†³ç­–çš„æ™ºèƒ½ä½“çš„çº¿æ€§ç´¢å¼•

        return:
            batch_landmark_nodes: List of Tensors, æ¯ä¸ª Tensor å½¢çŠ¶ä¸º [L_i, 4]ï¼Œä¸€å…±Batchä¸ªéœ€è¦å†³ç­–æ™ºèƒ½ä½“
                                  ç‰¹å¾ä¸º [relative_x, relative_y, utility, is_targeted]
            batch_landmark_nodes_masks: List of Tensors, æ¯ä¸ª Tensor å½¢çŠ¶ä¸º [L_i, 1]ï¼Œä¸€å…±Batchä¸ªéœ€è¦å†³ç­–æ™ºèƒ½ä½“
            å¦‚æœæœ‰æ™ºèƒ½ä½“æ²¡æœ‰æœ‰æ•ˆ landmarkï¼Œåˆ™å¯¹åº”çš„ Tensor å½¢çŠ¶ä¸º [1, 4] å’Œ [1, 1]ï¼Œå†…å®¹å…¨0ï¼ˆåç»­ä¼šè¢«maskæ‰ï¼‰
        """
        # ä»æ›´æ–°åçš„ landmark æ•°æ®ä¸­æå–å¯¹åº”çš„ landmarks
        batch_landmark_data = detected[linear_indices]  # [N, max_landmarks, 4]
        batch_landmark_mask = detected_mask[linear_indices]  # [N, max_landmarks, 1]
        
        # æå–å¯¹åº”æ™ºèƒ½ä½“çš„ä½ç½® [N, 2]
        ego_positions = agent_positions[linear_indices]  # [N, 2]

        batch_landmark_nodes = []
        batch_landmark_nodes_masks = []

        for i in range(len(linear_indices)):
            # è·å–æœ‰æ•ˆçš„ landmarks
            valid_mask = batch_landmark_mask[i, :, 0] > 0.5  # [max_landmarks]
            valid_landmarks = batch_landmark_data[i, valid_mask]  # [L_i, 4]ï¼ŒL_i æ˜¯è¯¥æ™ºèƒ½ä½“çš„æœ‰æ•ˆ landmark æ•°é‡
            
            if valid_landmarks.shape[0] > 0:
                # æå– landmark çš„ä¸–ç•Œåæ ‡ [L_i, 2]
                landmark_world_pos = valid_landmarks[:, :2]
                
                # è®¡ç®—ç›¸å¯¹ä½ç½®ï¼šlandmark_pos - agent_pos
                # ego_positions[i]: [2]
                # landmark_world_pos: [L_i, 2]
                relative_pos = landmark_world_pos - ego_positions[i].unsqueeze(0)  # [L_i, 2]
                
                # æ‹¼æ¥ç›¸å¯¹ä½ç½®å’Œå…¶ä»–ç‰¹å¾ï¼ˆutility, is_targetedï¼‰
                landmark_features = torch.cat([
                    relative_pos,              # [L_i, 2] - ç›¸å¯¹ä½ç½®
                    valid_landmarks[:, 2:]     # [L_i, 2] - utility, is_targeted
                ], dim=-1)  # [L_i, 4]
                
                batch_landmark_nodes.append(landmark_features)
                # åˆ›å»ºå…¨1çš„maskï¼Œè¡¨ç¤ºè¿™äº›éƒ½æ˜¯æœ‰æ•ˆèŠ‚ç‚¹
                batch_landmark_nodes_masks.append(torch.ones(valid_landmarks.shape[0], 1, device=valid_landmarks.device))
            else:
                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆ landmarkï¼Œæ·»åŠ ä¸€ä¸ªå ä½ç¬¦ï¼ˆåç»­ä¼šè¢«maskæ‰ï¼‰
                batch_landmark_nodes.append(torch.zeros(1, 4, device=batch_landmark_data.device))
                batch_landmark_nodes_masks.append(torch.zeros(1, 1, device=batch_landmark_data.device))

        return batch_landmark_nodes, batch_landmark_nodes_masks

    def get_edge_features(self, explore_nodes, landmark_nodes, landmark_node_masks, norm=False, max_distance=2.8):
        """
        è®¡ç®—è¾¹ç‰¹å¾
        
        Args:
            explore_nodes: [B, K, 4]ï¼Œå€™é€‰æ¢ç´¢ç‚¹ç‰¹å¾
            landmark_nodes: List of [L_i, 4]ï¼Œlandmark ç‰¹å¾ï¼Œæ¯ä¸ªLä¸å›ºå®š
            landmark_node_masks: List of [L_i, 1]ï¼Œlandmark æœ‰æ•ˆæ©ç 
            norm: æ˜¯å¦å½’ä¸€åŒ–è·ç¦»ï¼Œé»˜è®¤Falseï¼ˆä¸å½’ä¸€åŒ–ï¼‰
            max_distance: å½’ä¸€åŒ–æ—¶çš„æœ€å¤§è·ç¦»ï¼Œé»˜è®¤2.8
            
        Returns:
            batch_ego_to_explore_edges: List of [K, 3]
            batch_ego_to_landmark_edges: List of [L_i, 3]
            batch_ego_to_landmark_edge_masks: List of [L_i, 1]
        """
        # 1. ego -> explore nodes çš„è¾¹ç‰¹å¾
        batch_ego_to_explore_edges = []  # List of [K, 3]
        
        for i in range(explore_nodes.shape[0]):
            explore_relative_pos = explore_nodes[i, :, :2]  # [K, 2] - ç›¸å¯¹ä½ç½®
            
            # è®¡ç®—è·ç¦»
            distances = torch.norm(explore_relative_pos, dim=1, keepdim=True)  # [K, 1]
            
            # æ ¹æ® norm é€‰æ‹©è·ç¦»ç‰¹å¾
            if norm:
                d_feature = torch.clamp(distances / max_distance, max=1.0)  # [K, 1] å½’ä¸€åŒ–
            else:
                d_feature = distances  # [K, 1] åŸå§‹è·ç¦»
            
            # è®¡ç®—è§’åº¦çš„ cos å’Œ sinï¼ˆé¿å…é™¤é›¶ï¼‰
            distances_safe = distances.clamp(min=1e-6)
            cos_theta = explore_relative_pos[:, 0:1] / distances_safe  # [K, 1]
            sin_theta = explore_relative_pos[:, 1:2] / distances_safe  # [K, 1]
            
            # æ‹¼æ¥è¾¹ç‰¹å¾ [d, cos(Î¸), sin(Î¸)]
            edge_features = torch.cat([d_feature, cos_theta, sin_theta], dim=1)  # [K, 3]
            batch_ego_to_explore_edges.append(edge_features)
        
        # batch_ego_to_explore_edges: List of [K, 3], é•¿åº¦ä¸º N
        
        # 2. ego -> landmark nodes çš„è¾¹ç‰¹å¾
        batch_ego_to_landmark_edges = []  # List of [L_i, 3]
        batch_ego_to_landmark_edge_masks = []  # List of [L_i, 1]
        
        for i in range(len(landmark_nodes)):
            landmark_relative_pos = landmark_nodes[i][:, :2]  # [L_i, 2] - ç›¸å¯¹ä½ç½®
            landmark_mask = landmark_node_masks[i]  # [L_i, 1]
            
            # è®¡ç®—è·ç¦»
            distances = torch.norm(landmark_relative_pos, dim=1, keepdim=True)  # [L_i, 1]
            
            # æ ¹æ® norm é€‰æ‹©è·ç¦»ç‰¹å¾
            if norm:
                d_feature = torch.clamp(distances / max_distance, max=1.0)  # [L_i, 1] å½’ä¸€åŒ–
            else:
                d_feature = distances  # [L_i, 1] åŸå§‹è·ç¦»
            
            # è®¡ç®—è§’åº¦çš„ cos å’Œ sinï¼ˆé¿å…é™¤é›¶ï¼‰
            distances_safe = distances.clamp(min=1e-6)
            cos_theta = landmark_relative_pos[:, 0:1] / distances_safe  # [L_i, 1]
            sin_theta = landmark_relative_pos[:, 1:2] / distances_safe  # [L_i, 1]
            
            # æ‹¼æ¥è¾¹ç‰¹å¾ [d, cos(Î¸), sin(Î¸)]
            edge_features = torch.cat([d_feature, cos_theta, sin_theta], dim=1)  # [L_i, 3]
            
            batch_ego_to_landmark_edges.append(edge_features)
            batch_ego_to_landmark_edge_masks.append(landmark_mask)
        
        return batch_ego_to_explore_edges, batch_ego_to_landmark_edges, batch_ego_to_landmark_edge_masks

    def get_high_level_goal(self, batch_ego_nodes, 
                            batch_explore_nodes, batch_ego_to_explore_edges, 
                            batch_landmark_nodes, batch_landmark_node_masks, 
                            batch_ego_to_landmark_edges, batch_ego_to_landmark_edge_masks, 
                            deterministic=False):
        """
        ç»Ÿä¸€ä»æ‰€æœ‰å€™é€‰èŠ‚ç‚¹ï¼ˆexplore + landmarkï¼‰ä¸­é€‰æ‹©ä¸€ä¸ªç›®æ ‡
        
        Args:
            batch_ego_nodes: [B, 5] [x, y, vel_x, vel_y, battery]
            batch_explore_nodes: [B, K, 4] [relative_x, relative_y, utility, occupied]
            batch_ego_to_explore_edges: [B, K, 3] [d, cosÎ¸, sinÎ¸]
            batch_landmark_nodes: List[Tensor], æ¯ä¸ª [L_i, 4] [relative_x, relative_y, utility, is_targeted]
            batch_landmark_node_masks: List[Tensor], æ¯ä¸ª [L_i, 1] (1=æœ‰æ•ˆ, 0=æ— æ•ˆ)
            batch_ego_to_landmark_edges: List[Tensor], æ¯ä¸ª [L_i, 3]
            batch_ego_to_landmark_edge_masks: List[Tensor], æ¯ä¸ª [L_i, 1]
            deterministic: bool
        
        Returns:
            dict:
                action_modes: [B, 1] (0=explore, 1=landmark) è¢«é€‰ä¸­èŠ‚ç‚¹çš„ç±»å‹
                waypoints: [B, 2] ç»å¯¹ä¸–ç•Œåæ ‡
                decision_log_probs: [B, 1] èŠ‚ç‚¹é€‰æ‹©çš„ log_prob
                map_log_probs: [B, 1] åŒä¸Šï¼ˆä¿æŒæ¥å£å…¼å®¹ï¼‰
        """
        B = batch_ego_nodes.size(0)
        K = batch_explore_nodes.size(1)
        
        # ===== 1. èŠ‚ç‚¹å’Œè¾¹çš„ç‰¹å¾åµŒå…¥ =====
        # 1.1 EgoèŠ‚ç‚¹åµŒå…¥
        ego_node_feats = self.ego_node_encoder(batch_ego_nodes)  # [B, 64]
        
        # 1.2 ExploreèŠ‚ç‚¹åµŒå…¥
        explore_node_feats = self.explore_node_encoder(
            batch_explore_nodes.view(B * K, -1)
        ).view(B, K, -1)  # [B, K, 64]
        
        explore_edges_tensor = torch.stack(batch_ego_to_explore_edges, dim=0) # [B, K, 3]
        explore_edge_feats = self.edge_encoder(
            explore_edges_tensor.view(B * K, -1)
        ).view(B, K, -1)  # [B, K, 32]
        
        # 1.3 LandmarkèŠ‚ç‚¹åµŒå…¥ï¼ˆå¯å˜é•¿åº¦ï¼‰
        landmark_node_feats_list = []  # å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„ landmark ç‰¹å¾
        landmark_edge_feats_list = []
        landmark_lengths = []  # è®°å½•æ¯ä¸ªæ ·æœ¬çš„æœ‰æ•ˆ landmark æ•°é‡
        
        for i in range(B):
            node_feat = self.landmark_node_encoder(batch_landmark_nodes[i])  # [L_i, 64]
            edge_feat = self.edge_encoder(batch_ego_to_landmark_edges[i])    # [L_i, 32]
            landmark_node_feats_list.append(node_feat)
            landmark_edge_feats_list.append(edge_feat)
            landmark_lengths.append(node_feat.size(0))
        
        max_L = max(landmark_lengths) if landmark_lengths else 0
        
        # ===== 2. æ„å»ºç»Ÿä¸€çš„å€™é€‰èŠ‚ç‚¹é›†åˆ =====
        # å°† explore å’Œ landmark åˆå¹¶ä¸ºä¸€ä¸ªç»Ÿä¸€çš„èŠ‚ç‚¹é›†
        # æ€»èŠ‚ç‚¹æ•° = K (explore) + max_L (landmark)
        total_nodes = K + max_L
        
        # 2.1 å‡†å¤‡ Query
        q = self.q_proj(ego_node_feats).unsqueeze(1)  # [B, 1, 64]
        
        # 2.2 åˆå¹¶æ‰€æœ‰èŠ‚ç‚¹çš„ Key å’Œ Value
        # åˆå§‹åŒ–ç»Ÿä¸€çš„ K/V çŸ©é˜µ: [B, K+max_L, 64]
        unified_k = torch.zeros(B, total_nodes, self.attn_dim, device=ego_node_feats.device)
        unified_v = torch.zeros(B, total_nodes, self.attn_dim, device=ego_node_feats.device)
        unified_mask = torch.zeros(B, total_nodes, device=ego_node_feats.device, dtype=torch.bool)
        
        # å­˜å‚¨ç›¸å¯¹åæ ‡ç”¨äºåç»­è¾“å‡º
        unified_relative_pos = torch.zeros(B, total_nodes, 2, device=ego_node_feats.device)
        
        # èŠ‚ç‚¹ç±»å‹æ ‡ç­¾: 0=explore, 1=landmark
        node_type_labels = torch.zeros(B, total_nodes, device=ego_node_feats.device, dtype=torch.long)
        
        # å¡«å…… explore èŠ‚ç‚¹ (ç´¢å¼• 0 ~ K-1)
        explore_kv = torch.cat([explore_node_feats, explore_edge_feats], dim=-1)  # [B, K, 96]
        unified_k[:, :K, :] = self.k_proj(explore_kv.view(B * K, -1)).view(B, K, -1)
        unified_v[:, :K, :] = self.v_proj(explore_kv.view(B * K, -1)).view(B, K, -1)
        unified_mask[:, :K] = True  # explore èŠ‚ç‚¹å…¨éƒ¨æœ‰æ•ˆ
        unified_relative_pos[:, :K, :] = batch_explore_nodes[:, :, :2]  # ç›¸å¯¹åæ ‡
        node_type_labels[:, :K] = 0  # explore ç±»å‹
        
        # å¡«å…… landmark èŠ‚ç‚¹ (ç´¢å¼• K ~ K+max_L-1)
        for i in range(B):
            Li = landmark_lengths[i]
            if Li > 0:
                lm_kv = torch.cat([landmark_node_feats_list[i], landmark_edge_feats_list[i]], dim=-1)  # [Li, 96]
                unified_k[i, K:K+Li, :] = self.k_proj(lm_kv)
                unified_v[i, K:K+Li, :] = self.v_proj(lm_kv)
                # æœ‰æ•ˆçš„ landmarkï¼šå¿…é¡» mask æœ‰æ•ˆä¸”æœªè¢«è¿½è¸ª (is_targeted=0)
                valid_mask = batch_landmark_node_masks[i][:, 0] > 0.5
                not_targeted = batch_landmark_nodes[i][:, 3] < 0.5  # is_targeted åœ¨ç´¢å¼•3ï¼Œ<0.5è¡¨ç¤ºæœªè¢«è¿½è¸ª
                combined_mask = valid_mask & not_targeted
                unified_mask[i, K:K+Li] = combined_mask
                unified_relative_pos[i, K:K+Li, :] = batch_landmark_nodes[i][:, :2]
                node_type_labels[i, K:K+Li] = 1  # landmark ç±»å‹
        
        # ===== 3. æ³¨æ„åŠ›æœºåˆ¶ =====
        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        scale = math.sqrt(self.attn_dim)
        attn_scores = (q @ unified_k.transpose(1, 2)) / scale  # [B, 1, total_nodes]
        
        # åº”ç”¨ maskï¼ˆæ— æ•ˆèŠ‚ç‚¹è®¾ä¸º -infï¼‰
        attn_scores = attn_scores.masked_fill(~unified_mask.unsqueeze(1), -1e9)
        
        # Softmax å¾—åˆ°æ³¨æ„åŠ›æƒé‡
        attn_weights = torch.softmax(attn_scores, dim=-1)  # [B, 1, total_nodes]
        
        # æ³¨æ„åŠ›åŠ æƒæ±‚å’Œ
        context = (attn_weights @ unified_v).squeeze(1)  # [B, 64]
        
        # ===== 4. èŠ‚ç‚¹é€‰æ‹© =====
        # å¯¹æ‰€æœ‰èŠ‚ç‚¹è¿›è¡Œæ‰“åˆ†
        selection_logits = self.node_selection_head(unified_v).squeeze(-1)  # [B, total_nodes]
        
        # åº”ç”¨ mask
        selection_logits = selection_logits.masked_fill(~unified_mask, -1e9)
        
        # æ„å»ºåˆ†ç±»åˆ†å¸ƒ
        node_dist = TorchCategorical(logits=selection_logits)
        
        # é‡‡æ ·æˆ–é€‰æ‹©æœ€ä¼˜èŠ‚ç‚¹
        if deterministic:
            selected_idx = torch.argmax(selection_logits, dim=-1)  # [B]
        else:
            selected_idx = node_dist.sample()  # [B] or [B, 1]
        
        # ç¡®ä¿ selected_idx æ˜¯ [B] å½¢çŠ¶
        selected_idx = selected_idx.view(B)  # [B]
        
        # è®¡ç®— log_prob
        node_log_prob = node_dist.log_prob(selected_idx)  # [B]
        
        # ===== 5. æå–é€‰ä¸­èŠ‚ç‚¹çš„ä¿¡æ¯ =====
        batch_indices = torch.arange(B, device=ego_node_feats.device)
        
        # 5.1 èŠ‚ç‚¹ç±»å‹ (0=explore, 1=landmark)
        selected_type = node_type_labels[batch_indices, selected_idx]  # [B]
        
        # 5.2 ç›¸å¯¹åæ ‡
        selected_relative_pos = unified_relative_pos[batch_indices, selected_idx, :]  # [B, 2]
        
        # 5.3 è½¬æ¢ä¸ºç»å¯¹ä¸–ç•Œåæ ‡
        ego_pos = batch_ego_nodes[:, :2]  # [B, 2]
        waypoints_world = ego_pos + selected_relative_pos  # [B, 2]
        
        # ===== 6. è¿”å›ç»“æœ =====
        return {
            "action_modes": selected_type.unsqueeze(-1),       # [B, 1] èŠ‚ç‚¹ç±»å‹
            "waypoints": waypoints_world,                      # [B, 2] ç»å¯¹ä¸–ç•Œåæ ‡
            "node_log_probs": node_log_prob.unsqueeze(-1), # [B, 1] èŠ‚ç‚¹é€‰æ‹© log_prob
        }
    
    def get_high_value(self, map_inp, agent_states):
        """
        è®¡ç®—æ¯ä¸ªæ™ºèƒ½ä½“çš„çŠ¶æ€ä»·å€¼
        
        Args:
            map_inp: [B, 3, H, W] å…¨å±€åœ°å›¾ (entropy_map, heatmap, landmark_heatmap)
            agent_states: [B, num_agents, 4] æ™ºèƒ½ä½“çŠ¶æ€ [x, y, x_g, y_g]
        
        Returns:
            values: [B, num_agents] æ¯ä¸ªæ™ºèƒ½ä½“çš„ä»·å€¼ä¼°è®¡
        """
        B = map_inp.size(0)
        num_agents = agent_states.size(1)

        # 1. å…¨å±€åœ°å›¾ç‰¹å¾æå– [B, 3, H, W] -> [B, 256]
        f_map = self.critic_map_backbone(map_inp)  # [B, 64, 6, 6]
        f_map_flat = f_map.view(B, -1)  # [B, 64*6*6]
        f_global = self.critic_map_compress(f_map_flat)  # [B, 256]

        # 2. ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“è®¡ç®—ä»·å€¼
        values = []
        for agent_idx in range(num_agents):
            # 2.1 æå–è¯¥æ™ºèƒ½ä½“çš„çŠ¶æ€ [B, 4]
            agent_state = agent_states[:, agent_idx, :]  # [B, 4]
            
            # 2.2 ç¼–ç æ™ºèƒ½ä½“çŠ¶æ€ [B, 4] -> [B, 64]
            f_agent = self.critic_agent_encoder(agent_state)  # [B, 64]
            
            # 2.3 èåˆå…¨å±€ç‰¹å¾å’Œæ™ºèƒ½ä½“ç‰¹å¾ [B, 256] + [B, 64] -> [B, 320]
            fused = torch.cat([f_global, f_agent], dim=1)  # [B, 320]
            
            # 2.4 é€šè¿‡èåˆå±‚ [B, 320] -> [B, 128]
            h = self.critic_fusion_layer(fused)  # [B, 128]
            
            # 2.5 é€šè¿‡è¯¥æ™ºèƒ½ä½“çš„ç‹¬ç«‹ä»·å€¼å¤´ [B, 128] -> [B, 1]
            value = self.critic_value_out_heads[agent_idx](h)  # [B, 1]
            values.append(value)
        
        # 3. æ‹¼æ¥æ‰€æœ‰æ™ºèƒ½ä½“çš„ä»·å€¼ [B, num_agents]
        values = torch.cat(values, dim=1)  # [B, num_agents]

        return values

    def _low_value(self, x):
        return self.value_head(x) # h_dim -> h_dim -> 1

    def _low_policy(self, x): # h_dim -> h_dim
        return self.policy_head(x)
    
    def vec_inp_generator(self, env_state, detected_map):
        # ç”Ÿæˆæ™ºèƒ½ä½“å‘é‡æµï¼Œå¾—åˆ°vec_inp [num_agents, 5]ï¼Œ<x_pos, y_pos, B_candidate, x_target, y_target>
        # ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“åˆ†é…æœ€è¿‘çš„å·²å‘ç°ç›®æ ‡ç‚¹ä½œä¸ºç›®æ ‡ä½ç½®ï¼Œå·²å‘ç°ç›®æ ‡ç‚¹å¯èƒ½å°äºæ™ºèƒ½ä½“æ•°é‡
        # å¦‚æœæ²¡åˆ†é…åˆ°ï¼Œé»˜è®¤<x_pos, y_pos, 0, 0, 0>ï¼Œå¦åˆ™<x_pos, y_pos, 1, x_target, y_target>
        # æå–æ™ºèƒ½ä½“å½“å‰ä½ç½®, [num_agents, 2]
        agents_pos = env_state[self.num_agents * 2:self.num_agents * 4].view(self.num_agents, 2) 

        # æå–å·²å‘ç°ç›®æ ‡ç‚¹ä½ç½®, [num_detected, 2]
        detected_pos = detected_map.view(-1, 2)

        # è®¡ç®—æ™ºèƒ½ä½“åˆ°å·²å‘ç°ç›®æ ‡ç‚¹çš„è·ç¦»
        cost_matrix = torch.cdist(agents_pos, detected_pos, p=2)  # [num_agents, num_detected]

        # ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•è¿›è¡Œæœ€ä¼˜åˆ†é…
        cost_np = cost_matrix.cpu().numpy()
        row_ind, col_ind = linear_sum_assignment(cost_np)

        # ç”Ÿæˆæœ€ç»ˆçš„å‘é‡æµï¼Œé¦–å…ˆç”¨æ™ºèƒ½ä½“å½“å‰ä½ç½®åˆå§‹åŒ–
        vec_inp = torch.zeros((self.num_agents, 5), device=env_state.device)
        vec_inp[:, :2] = agents_pos

        # å¯¹äºè¢«åˆ†é…åˆ°ç›®æ ‡çš„æ™ºèƒ½ä½“ï¼Œæ›´æ–°å…¶å¤‡é€‰ç‚¹æ ‡è®°å’Œç›®æ ‡ä½ç½®
        for agent_idx, target_idx in zip(row_ind, col_ind):
            vec_inp[agent_idx, 2] = 1.0  # å¤‡é€‰ç‚¹æ ‡è®°
            vec_inp[agent_idx, 3:5] = detected_pos[target_idx]  # ç›®æ ‡ä½ç½®

        return vec_inp

    def data_processing_low_level(self, inp, goals):
        # inp: [num_agents*batch_size, dim_o]
        # goals: [num_agents*batch_size, 2], assigned goals for agents

        batch_size = inp.size(0)

        # æå–é€Ÿåº¦ [batch_size, 2]
        velocities = inp[:, 0:2]

        # æå–è‡ªèº«ä½ç½® [batch_size, 2]
        self_pos = inp[:, 2:4]

        # è®¡ç®—ä¸ç›®æ ‡çš„ç›¸å¯¹ä½ç½® [batch_size, 2]
        relative_goal_pos = goals - self_pos

        # æå–å…¶ä»–æ™ºèƒ½ä½“çš„ç»å¯¹ä½ç½®
        # ä» inp ä¸­æå–ï¼šè·³è¿‡é€Ÿåº¦(2)ã€è‡ªèº«ä½ç½®(2)ã€landmarks(num_agents*2)
        other_agents_start_idx = 4 + self.num_agents * 2
        other_agents_pos = inp[:, other_agents_start_idx:other_agents_start_idx + (self.num_agents - 1) * 2]

        # å°†å…¶ä»–æ™ºèƒ½ä½“ä½ç½®é‡å¡‘ä¸º [batch_size, num_agents-1, 2]
        other_agents_pos = other_agents_pos.view(batch_size, self.num_agents - 1, 2)

        # è®¡ç®—ä¸å…¶ä»–æ™ºèƒ½ä½“çš„ç›¸å¯¹ä½ç½®
        # æ‰©å±• self_pos ä»¥ä¾¿å¹¿æ’­: [batch_size, 1, 2]
        self_pos_expanded = self_pos.unsqueeze(1)

        # ç›¸å¯¹ä½ç½® [batch_size, num_agents-1, 2]
        relative_other_agents_pos = other_agents_pos - self_pos_expanded

        # å±•å¹³å…¶ä»–æ™ºèƒ½ä½“çš„ç›¸å¯¹ä½ç½® [batch_size, (num_agents-1)*2]
        relative_other_agents_pos = relative_other_agents_pos.view(batch_size, -1)

        # æ‹¼æ¥æ–°çš„è§‚æµ‹å‘é‡
        # [batch_size, 2 + 2 + (num_agents-1)*2]
        new_inp = torch.cat([
            velocities,                    # é€Ÿåº¦ (2)
            relative_goal_pos,             # ä¸ç›®æ ‡çš„ç›¸å¯¹ä½ç½® (2)
            relative_other_agents_pos      # ä¸å…¶ä»–æ™ºèƒ½ä½“çš„ç›¸å¯¹ä½ç½® ((num_agents-1)*2)
        ], dim=1)

        return new_inp

    def low_level_act(self, inp, goals, deterministic=False):
        """
        inp: [num_agents*batch_size, dim_o]
        state: [num_agents*batch_size, dim_h]
        goals: [num_agents*batch_size, 2], assigned goals for agents
        mask: [batch_size, 1], mask for actions
        
        """
        # å¤„ç†è§‚æµ‹å’Œç›®æ ‡ï¼Œå¾—åˆ°æ–°çš„è¾“å…¥
        new_inp = self.data_processing_low_level(inp, goals)  

        # å‰å‘ä¼ æ’­
        x = self.low_agent_encoder(new_inp)  # should be [batch_size, h_dim]
        value = self._low_value(x)  # should be [batch_size, 1]

        # é‡‡æ ·åŠ¨ä½œ
        dist = self.dist(self._low_policy(x))
        if deterministic:
            action = dist.mode()
        else:
            action = dist.sample()
        action_log_probs = dist.log_probs(action).view(-1,1)

        return value, action, action_log_probs

    def evaluate_high_actions(self, env_states, obs,
                              critic_maps, critic_nodes, goals, tasks, 
                              ego_nodes, explore_nodes, landmark_datas, landmark_masks, 
                              agent_ids):
        """
        è¯„ä¼°ç»™å®šé«˜å±‚åŠ¨ä½œçš„log_probã€ç†µå’Œä»·å€¼ï¼ˆç”¨äºPPOæ›´æ–°ï¼‰
        
        Input:
            env_states: [batch, env_dim]
            obs: [batch, obs_dim] - ç”¨äºæå–æ™ºèƒ½ä½“ä½ç½®
            critic_maps: [batch, 3, H, W] - ç”¨äºcritic
            critic_nodes: [batch, num_agents, 4] - ç”¨äºcritic
            goals: [batch, 2] - å·²é€‰æ‹©çš„ç›®æ ‡ä½ç½®ï¼ˆä¸–ç•Œåæ ‡ï¼‰
            tasks: [batch, 1] - å·²é€‰æ‹©çš„ä»»åŠ¡ç±»å‹ï¼ˆ0=explore, 1=landmarkï¼‰
            ego_nodes: [batch, 5]
            explore_nodes: [batch, K, 4]
            landmark_datas: [batch, num_landmarks, 4]
            landmark_masks: [batch, num_landmarks, 1]
            agent_ids: [batch, 1] - æ™ºèƒ½ä½“ID
            
        Returns:
            high_values: [batch, 1] - çŠ¶æ€ä»·å€¼
            node_log_probs: [batch, 1] - ç»™å®šèŠ‚ç‚¹é€‰æ‹©çš„logæ¦‚ç‡
            node_entropy: [batch, 1] - èŠ‚ç‚¹é€‰æ‹©åˆ†å¸ƒçš„ç†µ
        """
        batch_size = env_states.size(0)
        num_agents = self.num_agents
        K = explore_nodes.size(1)  # exploreèŠ‚ç‚¹æ•°é‡

        # =====================================================
        # 1. é‡å»ºGraph nodeså’ŒEdges
        # =====================================================
        # è·å– landmark nodes å’Œ masks
        landmark_nodes, landmark_node_masks = self.get_landmark_nodes(
            agent_positions=obs[:, 2:4],  # æå–æ™ºèƒ½ä½“å½“å‰ä½ç½®
            detected=landmark_datas,    
            detected_mask=landmark_masks,
            linear_indices=torch.arange(batch_size, device=env_states.device)
        )

        # è®¡ç®—è¾¹ç‰¹å¾
        ego_to_explore_edges, ego_to_landmark_edges, ego_to_landmark_edge_masks = self.get_edge_features(
            explore_nodes=explore_nodes,
            landmark_nodes=landmark_nodes,
            landmark_node_masks=landmark_node_masks,
            norm=False,
            max_distance=2.8
        )

        # =====================================================
        # 2. å¤ç”¨ get_high_level_goal çš„é€»è¾‘æ„å»ºèŠ‚ç‚¹åˆ†å¸ƒ
        # =====================================================
        B = batch_size
        
        # 2.1 èŠ‚ç‚¹å’Œè¾¹çš„ç‰¹å¾åµŒå…¥
        ego_node_feats = self.ego_node_encoder(ego_nodes)  # [B, 64]
        
        explore_node_feats = self.explore_node_encoder(
            explore_nodes.view(B * K, -1)
        ).view(B, K, -1)  # [B, K, 64]
        
        explore_edges_tensor = torch.stack(ego_to_explore_edges, dim=0)
        explore_edge_feats = self.edge_encoder(
            explore_edges_tensor.view(B * K, -1)
        ).view(B, K, -1)  # [B, K, 32]
        
        landmark_node_feats_list = []
        landmark_edge_feats_list = []
        landmark_lengths = []
        
        for i in range(B):
            node_feat = self.landmark_node_encoder(landmark_nodes[i])
            edge_feat = self.edge_encoder(ego_to_landmark_edges[i])
            landmark_node_feats_list.append(node_feat)
            landmark_edge_feats_list.append(edge_feat)
            landmark_lengths.append(node_feat.size(0))
        
        max_L = max(landmark_lengths) if landmark_lengths else 0
        
        # 2.2 æ„å»ºç»Ÿä¸€çš„å€™é€‰èŠ‚ç‚¹é›†åˆ
        total_nodes = K + max_L
        
        q = self.q_proj(ego_node_feats).unsqueeze(1)  # [B, 1, 64]
        
        unified_k = torch.zeros(B, total_nodes, self.attn_dim, device=ego_node_feats.device)
        unified_v = torch.zeros(B, total_nodes, self.attn_dim, device=ego_node_feats.device)
        unified_mask = torch.zeros(B, total_nodes, device=ego_node_feats.device, dtype=torch.bool)
        unified_relative_pos = torch.zeros(B, total_nodes, 2, device=ego_node_feats.device)
        
        # å¡«å…… explore èŠ‚ç‚¹
        explore_kv = torch.cat([explore_node_feats, explore_edge_feats], dim=-1)
        unified_k[:, :K, :] = self.k_proj(explore_kv.view(B * K, -1)).view(B, K, -1)
        unified_v[:, :K, :] = self.v_proj(explore_kv.view(B * K, -1)).view(B, K, -1)
        unified_mask[:, :K] = True
        unified_relative_pos[:, :K, :] = explore_nodes[:, :, :2]
        
        # å¡«å…… landmark èŠ‚ç‚¹
        for i in range(B):
            Li = landmark_lengths[i]
            if Li > 0:
                lm_kv = torch.cat([landmark_node_feats_list[i], landmark_edge_feats_list[i]], dim=-1)
                unified_k[i, K:K+Li, :] = self.k_proj(lm_kv)
                unified_v[i, K:K+Li, :] = self.v_proj(lm_kv)
                valid_mask = landmark_node_masks[i][:, 0] > 0.5
                not_targeted = landmark_nodes[i][:, 3] < 0.5
                combined_mask = valid_mask & not_targeted
                unified_mask[i, K:K+Li] = combined_mask
                unified_relative_pos[i, K:K+Li, :] = landmark_nodes[i][:, :2]
        
        # 2.3 æ³¨æ„åŠ›æœºåˆ¶
        scale = math.sqrt(self.attn_dim)
        attn_scores = (q @ unified_k.transpose(1, 2)) / scale
        attn_scores = attn_scores.masked_fill(~unified_mask.unsqueeze(1), -1e9)
        attn_weights = torch.softmax(attn_scores, dim=-1)
        context = (attn_weights @ unified_v).squeeze(1)
        
        # 2.4 èŠ‚ç‚¹é€‰æ‹©åˆ†å¸ƒ
        selection_logits = self.node_selection_head(unified_v).squeeze(-1)  # [B, total_nodes]
        selection_logits = selection_logits.masked_fill(~unified_mask, -1e9)
        node_dist = TorchCategorical(logits=selection_logits)
        
        # =====================================================
        # 3. æ‰¾åˆ°ç»™å®š goal å¯¹åº”çš„èŠ‚ç‚¹ç´¢å¼•
        # =====================================================
        # å°†ç»™å®šçš„ goals (ä¸–ç•Œåæ ‡) è½¬æ¢ä¸ºç›¸å¯¹åæ ‡
        ego_pos = ego_nodes[:, :2]  # [B, 2]
        goals_relative = goals - ego_pos  # [B, 2]
        
        # è®¡ç®— goals_relative åˆ°æ‰€æœ‰èŠ‚ç‚¹çš„è·ç¦»
        # unified_relative_pos: [B, total_nodes, 2]
        # goals_relative: [B, 2] -> [B, 1, 2]
        dists = torch.norm(unified_relative_pos - goals_relative.unsqueeze(1), dim=-1)  # [B, total_nodes]
        
        # åªåœ¨æœ‰æ•ˆèŠ‚ç‚¹ä¸­æŸ¥æ‰¾æœ€è¿‘çš„
        dists_masked = dists.masked_fill(~unified_mask, float('inf'))
        selected_idx = torch.argmin(dists_masked, dim=-1)  # [B]
        
        # =====================================================
        # 4. è®¡ç®— log_prob å’Œ entropy
        # =====================================================
        node_log_probs = node_dist.log_prob(selected_idx).unsqueeze(-1)  # [B, 1]
        node_entropy = node_dist.entropy().unsqueeze(-1)  # [B, 1]
        
        # =====================================================
        # 5. è®¡ç®— Critic ä»·å€¼
        # =====================================================
        # è®¡ç®—æ‰€æœ‰æ™ºèƒ½ä½“çš„ä»·å€¼ [B, num_agents]
        all_values = self.get_high_value(critic_maps, critic_nodes)  # [B, num_agents]
        
        # æ ¹æ® agent_ids é€‰æ‹©å¯¹åº”çš„ä»·å€¼
        agent_ids_flat = agent_ids.squeeze(-1)  # [B]
        batch_indices = torch.arange(B, device=env_states.device)
        high_values = all_values[batch_indices, agent_ids_flat].unsqueeze(-1)  # [B, 1]

        return (high_values, node_log_probs, node_entropy)
    
    def evaluate_low_actions(self, inp, goals, action):
        new_inp = self.data_processing_low_level(inp, goals)
        x = self.low_agent_encoder(new_inp)
        value = self._low_value(x)
        dist = self.dist(self._low_policy(x))
        action_log_probs = dist.log_probs(action)
        dist_entropy = dist.entropy().mean()
        
        return value, action_log_probs, dist_entropy
    
    def get_low_value(self, inp, goals):
        new_inp = self.data_processing_low_level(inp, goals)
        x = self.low_agent_encoder(new_inp)
        value = self._low_value(x)
        return value

    def _world_to_grid_torch(self, world_xy: torch.Tensor, H: int, W: int) -> torch.Tensor:
        """
        world_xy: [..., 2] in continuous world coords (x,y), assumed in [-arena_size/2, arena_size/2]
        return:  [..., 2] grid indices (i,j) as int64, clipped to [0..H-1/W-1]
        """
        world_min = -1.0
        cell_size_x = 2.0 / float(H)
        cell_size_y = 2.0 / float(W)

        x = world_xy[..., 0]
        y = world_xy[..., 1]

        i = torch.floor((x - world_min) / cell_size_x)
        j = torch.floor((y - world_min) / cell_size_y)

        i = i.clamp(0, H - 1)
        j = j.clamp(0, W - 1)

        return torch.stack([i, j], dim=-1).long()
    
    def _grid_to_world_torch(self, grid_ij: torch.Tensor, H: int, W: int) -> torch.Tensor:
        """
        grid_ij: [..., 2] grid indices (i,j) as int64
        return: [..., 2] in continuous world coords (x,y), in [-arena_size/2, arena_size/2]
        """
        world_min = -1.0
        cell_size_x = 2.0 / float(H)
        cell_size_y = 2.0 / float(W)

        i = grid_ij[..., 0].float()
        j = grid_ij[..., 1].float()

        x = world_min + (i + 0.5) * cell_size_x
        y = world_min + (j + 0.5) * cell_size_y

        return torch.stack([x, y], dim=-1)  

class MultiHeadAttention(nn.Module):
    # taken from https://github.com/wouterkool/attention-tsp/blob/master/graph_encoder.py
    def __init__(
            self,
            n_heads,
            input_dim,
            embed_dim=None,
            val_dim=None,
            key_dim=None
    ):
        super(MultiHeadAttention, self).__init__()

        if val_dim is None:
            assert embed_dim is not None, "Provide either embed_dim or val_dim"
            val_dim = embed_dim // n_heads
        if key_dim is None:
            key_dim = val_dim

        self.n_heads = n_heads
        self.input_dim = input_dim
        self.embed_dim = embed_dim
        self.val_dim = val_dim
        self.key_dim = key_dim

        self.norm_factor = 1 / math.sqrt(key_dim)  # See Attention is all you need

        self.W_query = nn.Parameter(torch.Tensor(n_heads, input_dim, key_dim))
        self.W_key = nn.Parameter(torch.Tensor(n_heads, input_dim, key_dim))
        self.W_val = nn.Parameter(torch.Tensor(n_heads, input_dim, val_dim))

        if embed_dim is not None:
            self.W_out = nn.Parameter(torch.Tensor(n_heads, key_dim, embed_dim))

        self.init_parameters()

    def init_parameters(self):

        for param in self.parameters():
            stdv = 1. / math.sqrt(param.size(-1))
            param.data.uniform_(-stdv, stdv)

    def forward(self, q, h=None, mask=None, return_attn=False):
        """
        :param q: queries (batch_size, n_query, input_dim)
        :param h: data (batch_size, graph_size, input_dim)
        :param mask: mask (batch_size, n_query, graph_size) or viewable as that (i.e. can be 2 dim if n_query == 1)
        Mask should contain 1 if attention is not possible (i.e. mask is negative adjacency)
        :return:
        """
        if h is None:
            h = q  # compute self-attention

        # h should be (batch_size, graph_size, input_dim)
        batch_size, graph_size, input_dim = h.size()
        n_query = q.size(1)
        assert q.size(0) == batch_size
        assert q.size(2) == input_dim
        assert input_dim == self.input_dim, "Wrong embedding dimension of input"

        hflat = h.contiguous().view(-1, input_dim)
        qflat = q.contiguous().view(-1, input_dim)

        # last dimension can be different for keys and values
        shp = (self.n_heads, batch_size, graph_size, -1)
        shp_q = (self.n_heads, batch_size, n_query, -1)

        # Calculate queries, (n_heads, n_query, graph_size, key/val_size)
        Q = torch.matmul(qflat, self.W_query).view(shp_q)
        # Calculate keys and values (n_heads, batch_size, graph_size, key/val_size)
        K = torch.matmul(hflat, self.W_key).view(shp)
        V = torch.matmul(hflat, self.W_val).view(shp)

        # Calculate compatibility (n_heads, batch_size, n_query, graph_size)
        compatibility = self.norm_factor * torch.matmul(Q, K.transpose(2, 3))
        # Optionally apply mask to prevent attention
        if mask is not None:
            mask = mask.contiguous().view(1, batch_size, n_query, graph_size).expand_as(compatibility)
            compatibility[mask] = -math.inf

        attn = F.softmax(compatibility, dim=-1)

        # If there are nodes with no neighbours then softmax returns nan so we fix them to 0
        if mask is not None:
            attnc = attn.clone()
            attnc[mask] = 0
            attn = attnc

        heads = torch.matmul(attn, V)

        out = torch.mm(
            heads.permute(1, 2, 0, 3).contiguous().view(-1, self.n_heads * self.val_dim),
            self.W_out.view(-1, self.embed_dim)
        ).view(batch_size, n_query, self.embed_dim)
        
        if return_attn:
            return out, attn
        return out
