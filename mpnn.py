import torch
import torch.nn as nn
import numpy as np
from rlcore.distributions import Categorical
import torch.nn.functional as F
import math
from scipy.optimize import linear_sum_assignment  # åŒˆç‰™åˆ©ç®—æ³•
from torch.distributions import Categorical as TorchCategorical

def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1 or classname.find('Linear') != -1:
        nn.init.orthogonal_(m.weight.data)
        if m.bias is not None:
            m.bias.data.fill_(0)


class MPNN(nn.Module):
    def __init__(self, action_space, num_agents, num_entities, input_size=16, hidden_dim=128, embed_dim=None,
                 pos_index=2, norm_in=False, nonlin=nn.ReLU, n_heads=3, mask_dist=None, mask_obs_dist=None, entity_mp=False, is_recurrent=True):
        super().__init__()

        # ==================== åŸºç¡€é…ç½® ====================
        self.h_dim = hidden_dim
        self.nonlin = nonlin
        self.num_agents = num_agents # number of agents
        self.num_entities = num_entities # number of entities
        self.low_level_input = 2 + 2*num_agents # low level input size: agent pos + all agents pos
        self.K = 3 # message passing rounds
        self.embed_dim = self.h_dim if embed_dim is None else embed_dim
        self.n_heads = n_heads
        self.is_recurrent = is_recurrent
        self.mask_dist = mask_dist
        self.mask_obs_dist = mask_obs_dist
        self.input_size = input_size # è¿™é‡Œæ˜¯agengtè‡ªèº«é€Ÿåº¦ä½ç½®ï¼ˆ4ï¼‰
        self.entity_mp = entity_mp
        # this index must be from the beginning of observation vector
        self.pos_index = pos_index
        # task generation parameters
        self.task_dim = 2
        self.h_dim2 = self.h_dim // 2 # 64
        num_actions = action_space.n

        # ==================== æ¨¡å—åŒ–ç½‘ç»œ ====================
        self.modules_dict = nn.ModuleDict()
        
        # 1. åº•å±‚ç­–ç•¥ç½‘ç»œ
        self.modules_dict['low_level'] = self._build_low_level_modules(action_space)
        
        # 2. é«˜å±‚ç­–ç•¥ç½‘ç»œ
        self.modules_dict['high_level'] = self._build_high_level_modules()
        
        # 3. é«˜å±‚ Critic
        self.modules_dict['high_critic'] = self._build_high_critic_modules()

        # ==================== å…¶ä»–å±æ€§ ====================
        if norm_in:
            self.in_fn = nn.BatchNorm1d(self.input_size)
            self.in_fn.weight.data.fill_(1)
            self.in_fn.bias.data.fill_(0)
        else:
            self.in_fn = lambda x: x
        self.apply(weights_init)
        self.attn_mat = np.ones((num_agents, num_agents))
        self.dropout_mask = None     
        

        # self.value_head = nn.Sequential(nn.Linear(self.h_dim, self.h_dim),
        #                                 self.nonlin(inplace=True),
        #                                 nn.Linear(self.h_dim,1))

        # self.policy_head = nn.Sequential(nn.Linear(self.h_dim, self.h_dim),
        #                                  self.nonlin(inplace=True))

        # self.low_agent_encoder = nn.Sequential(nn.Linear(self.low_level_input, self.h_dim),
        #                                       self.nonlin(inplace=True))
        
        # ==================== ä»£åŠ ====================
        self.dist = Categorical(self.h_dim,num_actions)

    # ==================== æ¨¡å—æ„å»ºå‡½æ•° ====================
    def _build_low_level_modules(self, action_space):
        """æ„å»ºåº•å±‚ç­–ç•¥ç½‘ç»œ"""
        num_actions = action_space.n
        low_level = nn.ModuleDict({
            'encoder': nn.Sequential(
                nn.Linear(self.low_level_input, self.h_dim),
                self.nonlin(inplace=True)
            ),
            'value_head': nn.Sequential(
                nn.Linear(self.h_dim, self.h_dim),
                self.nonlin(inplace=True),
                nn.Linear(self.h_dim, 1)
            ),
            'policy_head': nn.Sequential(
                nn.Linear(self.h_dim, self.h_dim),
                self.nonlin(inplace=True)
            ),
            'dist': Categorical(self.h_dim, num_actions)
        })
        
        return low_level

    def _build_high_level_modules(self):
        """æ„å»ºé«˜å±‚ç­–ç•¥ç½‘ç»œï¼ˆActorï¼‰"""
        high_level = nn.ModuleDict({
            # åœ°å›¾ç¼–ç å™¨
            'map_conv1': nn.Sequential(
                nn.Conv2d(4, 16, kernel_size=5, stride=2, padding=2),
                nn.ReLU()
            ),
            'map_conv2': nn.Sequential(
                nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),
                nn.ReLU()
            ),
            'map_conv3': nn.Sequential(
                nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=0),
                nn.ReLU()
            ),
            
            # å‘é‡ç¼–ç å™¨
            'vec_mlp': nn.Sequential(
                nn.Linear(5, 32),
                nn.ReLU(),
                nn.Linear(32, 64),
                nn.ReLU()
            ),
            
            # å†³ç­–å¤´
            'decision_head': nn.Sequential(
                nn.Linear(128, 64),
                nn.ReLU(),
                nn.Linear(64, 2)
            ),
            
            # æ¢ç´¢ç‚¹è§£ç å™¨
            'decoder_fuse': nn.Sequential(
                nn.Conv2d(192, 64, kernel_size=1),
                nn.ReLU()
            ),
            'decoder_up1': nn.Sequential(
                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),
                nn.Conv2d(64, 32, kernel_size=3, padding=1),
                nn.ReLU()
            ),
            'decoder_up2': nn.Sequential(
                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),
                nn.Conv2d(32, 16, kernel_size=3, padding=1),
                nn.ReLU()
            ),
            'decoder_out': nn.Sequential(
                nn.Upsample(size=(100, 100), mode='bilinear', align_corners=False),
                nn.Conv2d(16, 1, kernel_size=1)
            )
        })
        
        return high_level

    def _build_high_critic_modules(self):
        """æ„å»ºé«˜å±‚ Critic"""
        high_critic = nn.ModuleDict({
            'map_backbone': nn.Sequential(
                nn.Conv2d(4, 16, kernel_size=5, stride=2, padding=2),
                nn.ReLU(),
                nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),
                nn.ReLU(),
                nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
                nn.ReLU(),
                nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=0),
                nn.ReLU()
            ),
            'map_compress': nn.Sequential(
                nn.Linear(64 * 6 * 6, 256),
                nn.ReLU()
            ),
            'vec_encoder': nn.Sequential(
                nn.Linear(self.num_agents * 2 + self.num_agents * 2, 128),
                nn.ReLU(),
                nn.Linear(128, 128),
                nn.ReLU()
            ),
            'fusion_layer': nn.Sequential(
                nn.Linear(256 + 128, 256),
                nn.ReLU(),
                nn.Linear(256, 128),
                nn.ReLU()
            )
        })
        
        # æ¯ä¸ªæ™ºèƒ½ä½“çš„ç‹¬ç«‹è¾“å‡ºå¤´
        high_critic['value_heads'] = nn.ModuleList([
            nn.Linear(128, 1) for _ in range(self.num_agents)
        ])
        
        return high_critic

    # ==================== å‚æ•°ç®¡ç†æ¥å£ ====================
    
    def get_module_params(self, module_name):
        """
        è·å–æŒ‡å®šæ¨¡å—çš„å‚æ•°
        
        Args:
            module_name: 'shared', 'low_level', 'high_level', 'high_critic'
        
        Returns:
            list of parameters
        """
        if module_name not in self.modules_dict:
            raise ValueError(f"Module '{module_name}' not found! Available: {list(self.modules_dict.keys())}")
        
        return list(self.modules_dict[module_name].parameters())

    def freeze_module(self, module_name):
        """å†»ç»“æŒ‡å®šæ¨¡å—çš„å‚æ•°"""
        for param in self.get_module_params(module_name):
            param.requires_grad = False
        print(f"âœ… Module '{module_name}' frozen")

    def unfreeze_module(self, module_name):
        """è§£å†»æŒ‡å®šæ¨¡å—çš„å‚æ•°"""
        for param in self.get_module_params(module_name):
            param.requires_grad = True
        print(f"âœ… Module '{module_name}' unfrozen")

    def save_module_checkpoint(self, module_name, path):
        """
        ä¿å­˜æŒ‡å®šæ¨¡å—çš„å‚æ•°
        
        Args:
            module_name: æ¨¡å—åç§°
            path: ä¿å­˜è·¯å¾„
        """
        if module_name not in self.modules_dict:
            raise ValueError(f"Module '{module_name}' not found!")
        
        checkpoint = {
            'module_name': module_name,
            'state_dict': self.modules_dict[module_name].state_dict(),
            'config': {
                'num_agents': self.num_agents,
                'num_entities': self.num_entities,
                'hidden_dim': self.h_dim,
                'embed_dim': self.embed_dim
            }
        }
        
        torch.save(checkpoint, path)
        print(f"âœ… Saved '{module_name}' checkpoint to {path}")

    def load_module_checkpoint(self, module_name, path, strict=True, freeze=False):
        """
        åŠ è½½æŒ‡å®šæ¨¡å—çš„å‚æ•°
        
        Args:
            module_name: æ¨¡å—åç§°
            path: checkpoint è·¯å¾„
            strict: æ˜¯å¦ä¸¥æ ¼åŒ¹é…å‚æ•°
            freeze: æ˜¯å¦åŠ è½½åå†»ç»“
        
        Returns:
            missing_keys, unexpected_keys
        """
        checkpoint = torch.load(path, map_location='cpu')
        
        # éªŒè¯é…ç½®
        if 'config' in checkpoint:
            config = checkpoint['config']
            if config.get('num_agents') != self.num_agents:
                print(f"âš ï¸ Warning: num_agents mismatch! "
                      f"Checkpoint: {config['num_agents']}, Current: {self.num_agents}")
        
        # åŠ è½½å‚æ•°
        missing, unexpected = self.modules_dict[module_name].load_state_dict(
            checkpoint['state_dict'], 
            strict=strict
        )
        
        if freeze:
            self.freeze_module(module_name)
        
        print(f"âœ… Loaded '{module_name}' checkpoint from {path}")
        if missing:
            print(f"  Missing keys: {missing}")
        if unexpected:
            print(f"  Unexpected keys: {unexpected}")
        
        return missing, unexpected

    def save_all_modules(self, save_dir):
        """ä¿å­˜æ‰€æœ‰æ¨¡å—åˆ°æŒ‡å®šç›®å½•"""
        import os
        os.makedirs(save_dir, exist_ok=True)
        
        for module_name in self.modules_dict.keys():
            save_path = os.path.join(save_dir, f"{module_name}.pth")
            self.save_module_checkpoint(module_name, save_path)

    def load_pretrained_low_level(self, path, freeze=True):
        """
        æ™ºèƒ½åŠ è½½å‡½æ•°ï¼šæ”¯æŒåŠ è½½ 'æ¨¡å—åŒ–Checkpoint' æˆ– 'å®Œæ•´è®­ç»ƒCheckpoint'
        """
        print(f"ğŸ”„ Loading low-level params from {path}...")
        checkpoint = torch.load(path, map_location='cpu')
        
        low_level_state_dict = {}
        
        # === æƒ…å†µ A: è¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ– Checkpoint ===
        if 'state_dict' in checkpoint:
            print("  Type: Module Checkpoint")
            low_level_state_dict = checkpoint['state_dict']
            
        # === æƒ…å†µ B: è¿™æ˜¯ä¸€ä¸ªå®Œæ•´è®­ç»ƒ Checkpoint ===
        elif 'models' in checkpoint:
            print("  Type: Full Training Checkpoint (extracting params...)")
            full_state_dict = checkpoint['models'][0]
            
            # â­ å…³é”®ä¿®æ”¹ï¼šæ˜ç¡®åº•å±‚ç½‘ç»œçš„é”®åå‰ç¼€
            # æ—§ä»£ç ä¸­ï¼Œåº•å±‚ç½‘ç»œçš„é”®ååº”è¯¥æ˜¯ 'low_agent_encoder.*', 'value_head.*' ç­‰
            target_keys = [
                'low_agent_encoder',  # â† è¿™æ˜¯åº•å±‚ç¼–ç å™¨çš„çœŸæ­£åå­—
                'value_head',
                'policy_head',
                'dist'
            ]
            
            for key, value in full_state_dict.items():
                # å»é™¤å¯èƒ½çš„ 'modules_dict.low_level.' å‰ç¼€ï¼ˆå¦‚æœæ˜¯æ–°ç‰ˆä»£ç ä¿å­˜çš„ï¼‰
                clean_key = key.replace('modules_dict.low_level.', '')
                
                # æ£€æŸ¥æ˜¯å¦å±äºåº•å±‚ç½‘ç»œï¼ˆå¿…é¡»å®Œæ•´åŒ¹é…å‰ç¼€ï¼‰
                if any(clean_key.startswith(prefix) for prefix in target_keys):
                    # â­ å¦‚æœæ˜¯æ—§ä»£ç ï¼Œéœ€è¦å°† 'low_agent_encoder' æ˜ å°„ä¸º 'encoder'
                    # å› ä¸ºæ–°ä»£ç ä¸­åº•å±‚æ¨¡å—å†…éƒ¨çš„åå­—æ˜¯ 'encoder'
                    final_key = clean_key.replace('low_agent_encoder', 'encoder')
                    low_level_state_dict[final_key] = value
                    
        else:
            raise ValueError(f"Unknown checkpoint format! Keys found: {list(checkpoint.keys())}")

        # åŠ è½½å‚æ•°
        missing, unexpected = self.modules_dict['low_level'].load_state_dict(
            low_level_state_dict, 
            strict=False 
        )
        
        if freeze:
            self.freeze_module('low_level')
            
        print(f"âœ… Low-level loaded. Missing keys: {len(missing)}, Unexpected keys: {len(unexpected)}")
        if missing:
            print(f"  âš ï¸ Missing: {missing}")
        if unexpected:
            print(f"  âš ï¸ Unexpected: {unexpected}")
        
        return missing, unexpected
        """
        ä¾¿æ·å‡½æ•°ï¼šåŠ è½½é¢„è®­ç»ƒçš„åº•å±‚ç½‘ç»œ
        
        Args:
            path: checkpoint è·¯å¾„
            freeze: æ˜¯å¦å†»ç»“å‚æ•°
        """
        # return self.load_module_checkpoint('low_level', path, strict=False, freeze=freeze)

    def get_trainable_params_by_modules(self, module_names, learning_rates=None):
        """
        è·å–å¤šä¸ªæ¨¡å—çš„å‚æ•°ç»„ï¼ˆç”¨äºä¼˜åŒ–å™¨ï¼‰
        
        Args:
            module_names: æ¨¡å—åç§°åˆ—è¡¨
            learning_rates: å¯¹åº”çš„å­¦ä¹ ç‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            param_groups for optimizer
        
        Example:
            >>> param_groups = model.get_trainable_params_by_modules(
            ...     ['high_level', 'high_critic', 'low_level'],
            ...     [3e-4, 3e-4, 1e-5]  # åº•å±‚ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡
            ... )
            >>> optimizer = torch.optim.Adam(param_groups)
        """
        param_groups = []
        
        if learning_rates is None:
            learning_rates = [None] * len(module_names)
        
        for module_name, lr in zip(module_names, learning_rates):
            params = self.get_module_params(module_name)
            if lr is not None:
                param_groups.append({'params': params, 'lr': lr})
            else:
                param_groups.append({'params': params})
        
        return param_groups

    # ==================== å‰å‘ä¼ æ’­æ¥å£ï¼ˆä¿æŒå…¼å®¹ï¼‰====================
    
    @property
    def low_agent_encoder(self):
        return self.modules_dict['low_level']['encoder']
    
    @property
    def value_head(self):
        return self.modules_dict['low_level']['value_head']
    
    @property
    def policy_head(self):
        return self.modules_dict['low_level']['policy_head']
    
    @property
    def dist(self):
        return self.modules_dict['low_level']['dist']
    
    @property
    def map_conv1(self):
        return self.modules_dict['high_level']['map_conv1']
    
    @property
    def map_conv2(self):
        return self.modules_dict['high_level']['map_conv2']
    
    @property
    def map_conv3(self):
        return self.modules_dict['high_level']['map_conv3']
    
    @property
    def vec_mlp(self):
        return self.modules_dict['high_level']['vec_mlp']
    
    @property
    def decision_head(self):
        return self.modules_dict['high_level']['decision_head']
    
    @property
    def decoder_fuse(self):
        return self.modules_dict['high_level']['decoder_fuse']
    
    @property
    def decoder_up1(self):
        return self.modules_dict['high_level']['decoder_up1']
    
    @property
    def decoder_up2(self):
        return self.modules_dict['high_level']['decoder_up2']
    
    @property
    def decoder_out(self):
        return self.modules_dict['high_level']['decoder_out']
    
    @property
    def critic_map_backbone(self):
        return self.modules_dict['high_critic']['map_backbone']
    
    @property
    def critic_map_compress(self):
        return self.modules_dict['high_critic']['map_compress']
    
    @property
    def critic_vec_encoder(self):
        return self.modules_dict['high_critic']['vec_encoder']
    
    @property
    def critic_fusion_layer(self):
        return self.modules_dict['high_critic']['fusion_layer']
    
    @property
    def critic_value_out_heads(self):
        return self.modules_dict['high_critic']['value_heads']
    
    @property
    def critic_map_flat_dim(self):
        return 64 * 6 * 6
    
    @property
    def critic_vec_input_dim(self):
        return self.num_agents * 2 + self.num_agents * 2

    def high_level_forward(self, vec_inp, map_inp):
        """
        map_input: [Batch, 4, 100, 100] 
                   Channel 0: Belief Map 
                   Channel 1: Entropy Map
                   Channel 2: Voronoi Mask (0/1) 
                   Channel 3: Distance Field
        vec_input: [Batch, 5]
        """
        batch_size = map_inp.size(0)

        # ---------------------------
        # A. æå–ç‰¹å¾ (Backbone)
        # ---------------------------
        
        # 1. ç©ºé—´ç‰¹å¾ F_spatial: [B, 64, 12, 12]
        f_spatial = self.map_conv1(map_inp)
        f_spatial = self.map_conv2(f_spatial)
        f_spatial = self.map_conv3(f_spatial)

        # 2. å‘é‡ç‰¹å¾ f_vec: [B, 64]
        f_vec = self.vec_mlp(vec_inp)

        # ---------------------------
        # B. ç‰¹å¾èåˆ (Masked Pooling)
        # ---------------------------
        
        # 1. å–å‡ºåŸå§‹ Voronoi Mask (å‡è®¾æ˜¯ç¬¬2ä¸ªé€šé“) -> [B, 2, 100, 100]
        voronoi_mask_raw = map_inp[:, 2:3, :, :]

        # 2. ä¸‹é‡‡æ · Mask åˆ° 12x12ï¼Œæ¨¡å¼ä¸º nearest (ä¿æŒ 0/1 ç¡¬è¾¹ç•Œ)
        mask_down = F.interpolate(voronoi_mask_raw, size=(12, 12), mode='nearest')
        
        # 3. Masked Global Average Pooling
        # åªå¯¹ Voronoi åŒºåŸŸå†…çš„ç‰¹å¾æ±‚å’Œ
        masked_features = f_spatial * mask_down 
        sum_features = torch.sum(masked_features, dim=(2, 3)) # [B, 64]
        
        # è®¡ç®—åŒºåŸŸé¢ç§¯ (åƒç´ æ•°)ï¼ŒåŠ  epsilon é˜²æ­¢é™¤ä»¥ 0
        area = torch.sum(mask_down, dim=(2, 3)) + 1e-5 # [B, 1]
        
        # å¾—åˆ°å±€éƒ¨åŒºåŸŸçš„å¹³å‡ç‰¹å¾å‘é‡ v_map: [B, 64]
        v_map = sum_features / area 

        # 4. ç”Ÿæˆå…±äº«å‘é‡ h_shared: [B, 128]
        h_shared = torch.cat([v_map, f_vec], dim=1)

        # ---------------------------
        # C. å†³ç­–å¤´ (Decision Head)
        # ---------------------------
        
        # è¾“å‡º [Explore, Collect] çš„ Logits: [B, 2]
        decision_logits = self.decision_head(h_shared)

        # ---------------------------
        # D. æ¢ç´¢ç‚¹ç”Ÿæˆå¤´ (Waypoint Head)
        # ---------------------------
        
        # 1. å¹¿æ’­ h_shared åˆ°ç©ºé—´å°ºå¯¸: [B, 128, 12, 12]
        h_shared_expanded = h_shared.view(batch_size, 128, 1, 1).expand(-1, -1, 12, 12)
        
        # 2. æ‹¼æ¥ç©ºé—´ç‰¹å¾ä¸å…¨å±€ç‰¹å¾: [B, 192, 12, 12]
        decoder_in = torch.cat([f_spatial, h_shared_expanded], dim=1)
        
        # 3. è§£ç ç”Ÿæˆçƒ­åŠ›å›¾ Logits: [B, 1, 100, 100]
        x = self.decoder_fuse(decoder_in)
        x = self.decoder_up1(x)
        x = self.decoder_up2(x)
        heatmap_logits = self.decoder_out(x)

        # ---------------------------
        # E. åå¤„ç† (Masking)
        # ---------------------------
        
        # å…³é”®æ­¥éª¤ï¼šå†æ¬¡ä½¿ç”¨åŸå§‹ Voronoi Mask
        # å°†éåŠ¿åŠ›èŒƒå›´å†…çš„ Logits è®¾ä¸ºè´Ÿæ— ç©·
        # mask == 0 çš„åœ°æ–¹å¡«å…¥ -1e9
        heatmap_logits = heatmap_logits.masked_fill(voronoi_mask_raw == 0, -1e9)
        
        # å±•å¹³ä»¥ä¾¿åç»­é‡‡æ ·: [B, 10000]
        flat_heatmap_logits = heatmap_logits.view(batch_size, -1)

        return decision_logits, flat_heatmap_logits

    def get_high_level_goal(self, vec_inp, map_inp, deterministic=False):
        """
        é‡‡æ ·åŠ¨ä½œçš„è¾…åŠ©å‡½æ•° (ç”¨äº Rollout)
        """
        decision_logits, heatmap_logits = self.high_level_forward(vec_inp, map_inp)

        # ============================================================
        # åŸºäº B_candidate çš„åŠ¨ä½œæ©ç  (Action Masking)
        # å‘é‡æµç»“æ„: <x_pos, y_pos, B_candidate, x_target, y_target>
        # B_candidate ä½äºç´¢å¼• 2
        b_candidate = vec_inp[:, 2] # Shape: [Batch]

        # ä¸ºäº†ä¸ç ´åè®¡ç®—å›¾ï¼ˆå¦‚æœæ˜¯è®­ç»ƒè¿‡ç¨‹ï¼‰ï¼Œå»ºè®® clone ä¸€ä»½ logits
        # å¦‚æœåªæ˜¯æ¨ç† rolloutï¼Œä¸ clone ä¹Ÿå¯ä»¥ï¼Œä½† clone æ˜¯å¥½ä¹ æƒ¯
        masked_decision_logits = decision_logits.clone()

        # æ‰¾åˆ°æ²¡æœ‰å€™é€‰ç‚¹çš„æ ·æœ¬ç´¢å¼• (B_candidate == 0)
        # æ³¨æ„ï¼šæµ®ç‚¹æ•°æ¯”è¾ƒå»ºè®®ç”¨ < 0.5 æˆ–è€… iscloseï¼Œè¿™é‡Œå‡è®¾è¾“å…¥æ˜¯ä¸¥æ ¼çš„ 0/1
        mask_no_candidate = (b_candidate < 0.5) 

        # å°†è¿™äº›æ ·æœ¬çš„ COLLECT åŠ¨ä½œ (ç´¢å¼• 1) çš„ Logit è®¾ä¸ºè´Ÿæ— ç©·
        # -1e9 åœ¨ Softmax åä¼šå˜æˆ 0
        masked_decision_logits[mask_no_candidate, 1] = -1e9

        # ============================================================
        # é‡‡æ ·åŠ¨ä½œå¹¶è®¡ç®— log_probsï¼ˆå…³é”®ä¿®æ”¹ï¼‰
        # ============================================================
    
        # 1. å†³ç­–åŠ¨ä½œ
        decision_probs = F.softmax(masked_decision_logits, dim=-1)
        dist_mode = TorchCategorical(probs=decision_probs)
    
        if deterministic:
            action_mode = torch.argmax(decision_probs, dim=-1)
        else:
            action_mode = dist_mode.sample().squeeze(-1)    # [batch]



        # âœ… è®¡ç®—å†³ç­–åŠ¨ä½œçš„ log_prob
        decision_log_prob = dist_mode.log_prob(action_mode)  # [Batch]
    
        # 2. å¯¼èˆªç‚¹åŠ¨ä½œ
        heatmap_probs = F.softmax(heatmap_logits, dim=-1)   # [Batch, 10000]
        dist_map = TorchCategorical(probs=heatmap_probs)

        if deterministic:
            flat_idx = torch.argmax(heatmap_probs, dim=-1)
        else:
            flat_idx = dist_map.sample().squeeze(-1)    # [batch]
    
        # âœ… è®¡ç®—å¯¼èˆªç‚¹åŠ¨ä½œçš„ log_prob
        map_log_prob = dist_map.log_prob(flat_idx)  # [Batch]
    
        # 3. è½¬æ¢åæ ‡
        y_coords = torch.div(flat_idx, 100, rounding_mode='floor')  # å‘ä¸‹å–æ•´ï¼ˆæ¨èç”¨äºåæ ‡è®¡ç®—ï¼‰
        x_coords = flat_idx % 100
        if x_coords.dim() > 1:
            x_coords = x_coords.squeeze(-1)  # ç§»é™¤æœ€åä¸€ç»´
        if y_coords.dim() > 1:
            y_coords = y_coords.squeeze(-1)

        # 4. æ ¹æ®å†³ç­–è°ƒæ•´å¯¼èˆªç‚¹
        target_x = vec_inp[:, 3]
        target_y = vec_inp[:, 4]
        collect_mask = (action_mode == 1)  # [Batch]
        x_coords = torch.where(collect_mask, target_x.long(), x_coords)
        y_coords = torch.where(collect_mask, target_y.long(), y_coords)
        waypoints = torch.stack([x_coords, y_coords], dim=1).float()  # [Batch, 2]
        
        return {
            "action_modes": action_mode.unsqueeze(-1),              # [Batch, 1]
            "waypoints": waypoints,                   # [Batch,2]
            "decision_log_probs": decision_log_prob.unsqueeze(-1),  # âœ… [Batch, 1] æ ‡é‡
            "map_log_probs": map_log_prob.unsqueeze(-1)            # âœ… [Batch, 1] æ ‡é‡
        }
    
    def get_high_value(self, map_inp, vec_inp):
        # map_inp: [num_processes, 4, H, W]
        # vec_inp: [num_processes, num_agents*2 + num_landmarks*2]
        # è¿”å›ï¼š values: [num_processes, num_agents]
        batch_size = map_inp.size(0)

        # å…¨å±€åœ°å›¾ç¼–ç å™¨
        f_map = self.critic_map_backbone(map_inp)  # [B, 64, 6, 6]
        f_map_flat = f_map.view(batch_size, -1)  # [B, 64*6*6]
        f_map_compress = self.critic_map_compress(f_map_flat)  # [B, 256]

        # ç»“åˆå…¨å±€åœ°å›¾ç‰¹å¾å’Œå±€éƒ¨ç‰¹å¾
        f_vec = self.critic_vec_encoder(vec_inp)  # [B, 128]
        f_fuse = torch.cat([f_map_compress, f_vec], dim=1)  # [B, 256 + 128]

        fused = self.critic_fusion_layer(f_fuse)    # [B, 128]

        # ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“è®¡ç®—ç‹¬ç«‹çš„ä»·å€¼
        values = []
        for agent_idx in range(self.num_agents):
            value = self.critic_value_out_heads[agent_idx](fused)  # [B, 1]
            values.append(value)
        values = torch.cat(values, dim=1)  # [B, num_agents]

        return values

    def _low_value(self, x):
        return self.value_head(x) # h_dim -> h_dim -> 1

    def _low_policy(self, x): # h_dim -> h_dim
        return self.policy_head(x)
    
    def vec_inp_generator(self, env_state, detected_map):
        # ç”Ÿæˆæ™ºèƒ½ä½“å‘é‡æµï¼Œå¾—åˆ°vec_inp [num_agents, 5]ï¼Œ<x_pos, y_pos, B_candidate, x_target, y_target>
        # ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“åˆ†é…æœ€è¿‘çš„å·²å‘ç°ç›®æ ‡ç‚¹ä½œä¸ºç›®æ ‡ä½ç½®ï¼Œå·²å‘ç°ç›®æ ‡ç‚¹å¯èƒ½å°äºæ™ºèƒ½ä½“æ•°é‡
        # å¦‚æœæ²¡åˆ†é…åˆ°ï¼Œé»˜è®¤<x_pos, y_pos, 0, 0, 0>ï¼Œå¦åˆ™<x_pos, y_pos, 1, x_target, y_target>
        # æå–æ™ºèƒ½ä½“å½“å‰ä½ç½®, [num_agents, 2]
        agents_pos = env_state[self.num_agents * 2:self.num_agents * 4].view(self.num_agents, 2) 

        # æå–å·²å‘ç°ç›®æ ‡ç‚¹ä½ç½®, [num_detected, 2]
        detected_pos = detected_map.view(-1, 2)

        # è®¡ç®—æ™ºèƒ½ä½“åˆ°å·²å‘ç°ç›®æ ‡ç‚¹çš„è·ç¦»
        cost_matrix = torch.cdist(agents_pos, detected_pos, p=2)  # [num_agents, num_detected]

        # ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•è¿›è¡Œæœ€ä¼˜åˆ†é…
        cost_np = cost_matrix.cpu().numpy()
        row_ind, col_ind = linear_sum_assignment(cost_np)

        # ç”Ÿæˆæœ€ç»ˆçš„å‘é‡æµï¼Œé¦–å…ˆç”¨æ™ºèƒ½ä½“å½“å‰ä½ç½®åˆå§‹åŒ–
        vec_inp = torch.zeros((self.num_agents, 5), device=env_state.device)
        vec_inp[:, :2] = agents_pos

        # å¯¹äºè¢«åˆ†é…åˆ°ç›®æ ‡çš„æ™ºèƒ½ä½“ï¼Œæ›´æ–°å…¶å¤‡é€‰ç‚¹æ ‡è®°å’Œç›®æ ‡ä½ç½®
        for agent_idx, target_idx in zip(row_ind, col_ind):
            vec_inp[agent_idx, 2] = 1.0  # å¤‡é€‰ç‚¹æ ‡è®°
            vec_inp[agent_idx, 3:5] = detected_pos[target_idx]  # ç›®æ ‡ä½ç½®

        return vec_inp

    def data_processing_low_level(self, inp, goals):
        # inp: [num_agents*batch_size, dim_o]
        # goals: [num_agents*batch_size, 2], assigned goals for agents

        batch_size = inp.size(0)

        # æå–é€Ÿåº¦ [batch_size, 2]
        velocities = inp[:, 0:2]

        # æå–è‡ªèº«ä½ç½® [batch_size, 2]
        self_pos = inp[:, 2:4]

        # è®¡ç®—ä¸ç›®æ ‡çš„ç›¸å¯¹ä½ç½® [batch_size, 2]
        relative_goal_pos = goals - self_pos

        # æå–å…¶ä»–æ™ºèƒ½ä½“çš„ç»å¯¹ä½ç½®
        # ä» inp ä¸­æå–ï¼šè·³è¿‡é€Ÿåº¦(2)ã€è‡ªèº«ä½ç½®(2)ã€landmarks(num_agents*2)
        other_agents_start_idx = 4 + self.num_agents * 2
        other_agents_pos = inp[:, other_agents_start_idx:other_agents_start_idx + (self.num_agents - 1) * 2]

        # å°†å…¶ä»–æ™ºèƒ½ä½“ä½ç½®é‡å¡‘ä¸º [batch_size, num_agents-1, 2]
        other_agents_pos = other_agents_pos.view(batch_size, self.num_agents - 1, 2)

        # è®¡ç®—ä¸å…¶ä»–æ™ºèƒ½ä½“çš„ç›¸å¯¹ä½ç½®
        # æ‰©å±• self_pos ä»¥ä¾¿å¹¿æ’­: [batch_size, 1, 2]
        self_pos_expanded = self_pos.unsqueeze(1)

        # ç›¸å¯¹ä½ç½® [batch_size, num_agents-1, 2]
        relative_other_agents_pos = other_agents_pos - self_pos_expanded

        # å±•å¹³å…¶ä»–æ™ºèƒ½ä½“çš„ç›¸å¯¹ä½ç½® [batch_size, (num_agents-1)*2]
        relative_other_agents_pos = relative_other_agents_pos.view(batch_size, -1)

        # æ‹¼æ¥æ–°çš„è§‚æµ‹å‘é‡
        # [batch_size, 2 + 2 + (num_agents-1)*2]
        new_inp = torch.cat([
            velocities,                    # é€Ÿåº¦ (2)
            relative_goal_pos,             # ä¸ç›®æ ‡çš„ç›¸å¯¹ä½ç½® (2)
            relative_other_agents_pos      # ä¸å…¶ä»–æ™ºèƒ½ä½“çš„ç›¸å¯¹ä½ç½® ((num_agents-1)*2)
        ], dim=1)

        return new_inp

    def low_level_act(self, inp, goals, deterministic=False):
        """
        inp: [num_agents*batch_size, dim_o]
        state: [num_agents*batch_size, dim_h]
        goals: [num_agents*batch_size, 2], assigned goals for agents
        mask: [batch_size, 1], mask for actions
        
        """
        # å¤„ç†è§‚æµ‹å’Œç›®æ ‡ï¼Œå¾—åˆ°æ–°çš„è¾“å…¥
        new_inp = self.data_processing_low_level(inp, goals)  

        # å‰å‘ä¼ æ’­
        x = self.low_agent_encoder(new_inp)  # should be [batch_size, h_dim]
        value = self._low_value(x)  # should be [batch_size, 1]

        # é‡‡æ ·åŠ¨ä½œ
        dist = self.dist(self._low_policy(x))
        if deterministic:
            action = dist.mode()
        else:
            action = dist.sample()
        action_log_probs = dist.log_probs(action).view(-1,1)

        return value, action, action_log_probs

    def evaluate_high_actions(self, env_states, map_obs, vec_obs, critic_maps, goals, tasks, agent_ids):
        """
        Input:
            env_states: [batch, env_dim]
            map_obs: [batch, 4, H, W]
            vec_obs: [batch, 5] 
            agent_ids: [batch, 1]
        è¯„ä¼°é«˜å±‚åŠ¨ä½œ
        Returns:
            high_values: [batch, 1]
            decision_log_probs: [batch, 1]
            map_log_probs: [batch, 1]
            decision_entropy: [batch] â† æ”¹ä¸ºæ¯ä¸ªæ ·æœ¬çš„ç†µ
            waypoint_entropy: [batch] â† æ”¹ä¸ºæ¯ä¸ªæ ·æœ¬çš„ç†µ
        """
        batch_size = map_obs.size(0)
        num_agents = self.num_agents

        # =====================================================
        # 1. Critic: è®¡ç®—æ‰€æœ‰æ™ºèƒ½ä½“çš„ä»·å€¼ [batch, num_agents]
        # =====================================================
        critic_vec = env_states[:, 2*num_agents:]  # æå–å…¨å±€å‘é‡ä¿¡æ¯
        all_values = self.get_high_value(critic_maps, critic_vec)  # [batch, num_agents]
        
        # â­ æ ¹æ® agent_ids é€‰æ‹©å¯¹åº”çš„ä»·å€¼
        agent_ids_expanded = agent_ids.unsqueeze(-1)  # [batch, 1]
        high_values = torch.gather(all_values, dim=1, index=agent_ids_expanded)  # [batch, 1]

        # =====================================================
        # 2. Actor: å‰å‘ä¼ æ’­è·å– logits
        # =====================================================
        decision_logits, heatmap_logits = self.high_level_forward(vec_obs, map_obs)
        # decision_logits: [batch, 2]
        # heatmap_logits: [batch, 10000]

        # =====================================================
        # 3. åº”ç”¨åŠ¨ä½œæ©ç  (Action Masking)
        # =====================================================
        b_candidate = vec_obs[:, 2]  # [batch]
        masked_decision_logits = decision_logits.clone()
        
        # å°†æ²¡æœ‰å€™é€‰ç‚¹çš„æ ·æœ¬çš„ COLLECT åŠ¨ä½œè®¾ä¸ºè´Ÿæ— ç©·
        mask_no_candidate = (b_candidate < 0.5)
        masked_decision_logits[mask_no_candidate, 1] = -1e9

        # =====================================================
        # 4. è®¡ç®—å†³ç­–å¤´çš„ log_probs å’Œ entropy
        # =====================================================
        decision_probs = F.softmax(masked_decision_logits, dim=-1)  # [batch, 2]
        dist_decision = TorchCategorical(probs=decision_probs)
        
        # è®¡ç®—ç»™å®šåŠ¨ä½œçš„ log_prob
        decision_log_probs = dist_decision.log_prob(tasks.squeeze(-1))  # [batch]
        
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ç†µ
        decision_entropy = dist_decision.entropy()  # [batch]

        # =====================================================
        # 5. è®¡ç®—æ¢ç´¢å¤´çš„ log_probs å’Œ entropy
        # =====================================================
        heatmap_probs = F.softmax(heatmap_logits, dim=-1)  # [batch, 10000]
        dist_map = TorchCategorical(probs=heatmap_probs)
        
        # å°† goals [batch, 2] è½¬æ¢ä¸º flat_idx [batch]
        goals_x = goals[:, 0].long()  # [batch]
        goals_y = goals[:, 1].long()  # [batch]
        flat_idx = goals_y * 100 + goals_x  # [batch]
        
        # è®¡ç®—ç»™å®šå¯¼èˆªç‚¹çš„ log_prob
        map_log_probs = dist_map.log_prob(flat_idx)  # [batch]
        
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ç†µ
        waypoint_entropy = dist_map.entropy()  # [batch]

        return (high_values, decision_log_probs, map_log_probs, 
                decision_entropy, waypoint_entropy)
    
    def evaluate_low_actions(self, inp, goals, action):
        new_inp = self.data_processing_low_level(inp, goals)
        x = self.low_agent_encoder(new_inp)
        value = self._low_value(x)
        dist = self.dist(self._low_policy(x))
        action_log_probs = dist.log_probs(action)
        dist_entropy = dist.entropy().mean()
        
        return value, action_log_probs, dist_entropy
    
    def get_low_value(self, inp, goals):
        new_inp = self.data_processing_low_level(inp, goals)
        x = self.low_agent_encoder(new_inp)
        value = self._low_value(x)
        return value


class MultiHeadAttention(nn.Module):
    # taken from https://github.com/wouterkool/attention-tsp/blob/master/graph_encoder.py
    def __init__(
            self,
            n_heads,
            input_dim,
            embed_dim=None,
            val_dim=None,
            key_dim=None
    ):
        super(MultiHeadAttention, self).__init__()

        if val_dim is None:
            assert embed_dim is not None, "Provide either embed_dim or val_dim"
            val_dim = embed_dim // n_heads
        if key_dim is None:
            key_dim = val_dim

        self.n_heads = n_heads
        self.input_dim = input_dim
        self.embed_dim = embed_dim
        self.val_dim = val_dim
        self.key_dim = key_dim

        self.norm_factor = 1 / math.sqrt(key_dim)  # See Attention is all you need

        self.W_query = nn.Parameter(torch.Tensor(n_heads, input_dim, key_dim))
        self.W_key = nn.Parameter(torch.Tensor(n_heads, input_dim, key_dim))
        self.W_val = nn.Parameter(torch.Tensor(n_heads, input_dim, val_dim))

        if embed_dim is not None:
            self.W_out = nn.Parameter(torch.Tensor(n_heads, key_dim, embed_dim))

        self.init_parameters()

    def init_parameters(self):

        for param in self.parameters():
            stdv = 1. / math.sqrt(param.size(-1))
            param.data.uniform_(-stdv, stdv)

    def forward(self, q, h=None, mask=None, return_attn=False):
        """
        :param q: queries (batch_size, n_query, input_dim)
        :param h: data (batch_size, graph_size, input_dim)
        :param mask: mask (batch_size, n_query, graph_size) or viewable as that (i.e. can be 2 dim if n_query == 1)
        Mask should contain 1 if attention is not possible (i.e. mask is negative adjacency)
        :return:
        """
        if h is None:
            h = q  # compute self-attention

        # h should be (batch_size, graph_size, input_dim)
        batch_size, graph_size, input_dim = h.size()
        n_query = q.size(1)
        assert q.size(0) == batch_size
        assert q.size(2) == input_dim
        assert input_dim == self.input_dim, "Wrong embedding dimension of input"

        hflat = h.contiguous().view(-1, input_dim)
        qflat = q.contiguous().view(-1, input_dim)

        # last dimension can be different for keys and values
        shp = (self.n_heads, batch_size, graph_size, -1)
        shp_q = (self.n_heads, batch_size, n_query, -1)

        # Calculate queries, (n_heads, n_query, graph_size, key/val_size)
        Q = torch.matmul(qflat, self.W_query).view(shp_q)
        # Calculate keys and values (n_heads, batch_size, graph_size, key/val_size)
        K = torch.matmul(hflat, self.W_key).view(shp)
        V = torch.matmul(hflat, self.W_val).view(shp)

        # Calculate compatibility (n_heads, batch_size, n_query, graph_size)
        compatibility = self.norm_factor * torch.matmul(Q, K.transpose(2, 3))
        # Optionally apply mask to prevent attention
        if mask is not None:
            mask = mask.contiguous().view(1, batch_size, n_query, graph_size).expand_as(compatibility)
            compatibility[mask] = -math.inf

        attn = F.softmax(compatibility, dim=-1)

        # If there are nodes with no neighbours then softmax returns nan so we fix them to 0
        if mask is not None:
            attnc = attn.clone()
            attnc[mask] = 0
            attn = attnc

        heads = torch.matmul(attn, V)

        out = torch.mm(
            heads.permute(1, 2, 0, 3).contiguous().view(-1, self.n_heads * self.val_dim),
            self.W_out.view(-1, self.embed_dim)
        ).view(batch_size, n_query, self.embed_dim)
        
        if return_attn:
            return out, attn
        return out
